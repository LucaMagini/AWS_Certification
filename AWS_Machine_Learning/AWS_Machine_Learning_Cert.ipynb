{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "DSLvm0OAvj_O",
        "KMoZNBhhA122",
        "ZZy5sc-Wcfg2",
        "u7JTMlc0BsmE",
        "nvHiWuMBY8BK",
        "cvVYzX63lhhV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AWS MACHINE LEARNING CERTIFICATION"
      ],
      "metadata": {
        "id": "tnkW2Hj8vGAV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. DATA ENGINEERING"
      ],
      "metadata": {
        "id": "DSLvm0OAvj_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AMAZON S3**\n",
        "* **What is S3?**\n",
        "  * Store Objects (Files) in Buckets (Directories)\n",
        "  * Buckets must have globally unique name\n",
        "  * Max object size is 5 TB\n",
        "  * Object Tags (key/value pair - up to 10) - useful for security/lifecycle\n",
        "* **Amazon S3 for Machine Learning**\n",
        "  * Backbone for many AWS ML Services \n",
        "  * Create a Data Lake\n",
        "    * Infinite size\n",
        "    * 99.999999999% durability\n",
        "    * Decoupling of storage (S3) to compute (EC2, Athena, Rekognition, Glue)\n",
        "  * Centralized Architecture\n",
        "  * Object Storage: supports any file format\n",
        "  * Common formats for ML: CSV, JSON, Parquet, ORC, Avro, Protobuf\n",
        "* **Amazon S3 for Data Partitioning**\n",
        "  * Pattern for speeding up range queries (AWS Athena)\n",
        "  * By Date: s3://bucket/my-data/year/month/day/hour/data_00.csv\n",
        "  * By Product: s3://bucket/my-data/product-id/data_32.csv\n",
        "  * You can define whatever partitioning strategy you like\n",
        "  * Data partitioning will be handled by some tools we use (AWS Glue)\n",
        "* **Storage Classes**\n",
        "\n",
        "Can move between classes manually or using S3 Lifecycle configurations\n",
        "  * *Standard - General Purpose*\n",
        "    * 99.99% availability\n",
        "    * Used for frequently accessed data\n",
        "    * Low latency and high throughput\n",
        "    * Sustain 2 concurrent facility failures \n",
        "    * Use cases: Big data analytics, mobile & gaming applications \n",
        "  * *Standard - Infrequent Access (IA)*\n",
        "    * For data that is less frequently accessed but requires rapid access when needed\n",
        "    * Lower cost than S3 Standard\n",
        "    * 99.99% availability\n",
        "    * Use cases: Disaster Recovery, Backups\n",
        "  * *One Zone Infrequent Access*\n",
        "    * For data that is less frequently accessed but requires rapid access when needed\n",
        "    * Lower cost than S3 Standard\n",
        "    * High durability in a single AZ but data lost when AZ is destroyed\n",
        "    * Use cases: Storing secondary backup copies of on-premise data or data you can recreate \n",
        "  * *Glacier Instant Retrieval*\n",
        "    * Low-cost object storage meant for archiving/backup\n",
        "    * Pricing: price for storage + object retrieval cost\n",
        "    * Millisecond retrieval, great for data accessed once a quarter\n",
        "    * Minimum storage duration of 90 days\n",
        "  * *Glacier Flexible Retrieval*\n",
        "    * Low-cost object storage meant for archiving/backup\n",
        "    * Pricing: price for storage + object retrieval cost\n",
        "    * Expited (1-5 minutes), Standard (3-5 hours), Bulk (5-12 hours) - free\n",
        "    * Minimum storage duration of 90 days\n",
        "  * *Glacier Deep Archive*\n",
        "    * Low-cost object storage meant for archiving/backup\n",
        "    * Pricing: price for storage + object retrieval cost\n",
        "    * Standard (12 hours), Bulk (48 hours)\n",
        "    * Minimum storage duration of 180 days \n",
        "  * *Intelligent Tiering*\n",
        "    * Small monthly monitoring and auto-tiering fee\n",
        "    * Moves objects automatically between Access Tiers based on usage\n",
        "    * There are no retrieval charges\n",
        "    * Strategy:\n",
        "      * Frequent Access tier (automatic): default tier\n",
        "      * Infrequent Access tier (automatic): objects not accessed for 30 days\n",
        "      * Archive Instant Access tier (automatic): objects not accessed for 90 days\n",
        "      * Archive Access tier (optional): configurable from 90 to 700+ days\n",
        "      * Deep Archive Access tier (optional): config. from 180 to 700+ days \n",
        "* **Durability vs Availability**\n",
        "  * *Durability*\n",
        "    * It represents how many times an object is going to be lost in S3\n",
        "    * High durability (99.999999999%) of objects across multiple AZ\n",
        "    * Same for all storage classes\n",
        "  * *Availability*   \n",
        "    * It measures how readily available a service is\n",
        "    * Varies depending on storage class\n",
        "    * E.g. S3 standard has 99.99% availability = not available 53 minutes a year\n",
        "\n",
        "* **Lifecycle Rules**\n",
        "  * You can transition objects between storage classes\n",
        "  * For infrequently accessed object, move them to standard IA\n",
        "  * For archive objects that you don't need fast access to, move them to Glacier or Glacier Deep Archive\n",
        "  * Moving objects can be automated using a Lifecycle Rules\n",
        "  * *Transition Actions*\n",
        "    * Configure objects to transition to another storage class\n",
        "    * Move objects to Standard IA class 60 days after creation\n",
        "    * Move to Glacier for archiving after 6 months\n",
        "  * *Expiration Actions*\n",
        "    * Configure objects to expire (delete) after some time\n",
        "    * Access log files can be set to delete after a 365 days\n",
        "    * Can be used to delete old version of files (if versioning enabled)\n",
        "    * Can be used to delete incomplete Multi-Part uploads\n",
        "\n",
        "Rules can be created for certain prefix (e.g. s3://mybucket/mp3/*) or for certain objects tags (e.g. Department: Finance)\n",
        "\n",
        "* **S3 Analytics - Storage Class Analysis**\n",
        "  * Help you decide when to transition objects to the right storage class\n",
        "  * Recommendations for Standard and Standard IA (don't work for One-Zone IA or Glacier)\n",
        "  * Report is updated daily\n",
        "  * 24 to 48 hours to start seeing analysis\n",
        "\n",
        "<br>\n",
        "\n",
        "If objects have a **defined lifecycle**, such as needing frequent access for a month and then never needing to be accessed again, a lifecycle policy is the most efficient and cost-effective solution for you.\n",
        "\n",
        "Else if access patterns are unpredictable or difficult to identify, **Intelligent Tiering** is an excellent solution for hands-off storage access monitoring while still taking advantage of cost savings from S3-IA.  \n",
        "\n",
        "* **S3 Security - Encryption**\n",
        "  * S3 Encryption for Object (4 methods)\n",
        "    * *SSE-S3*: encrypts S3 objects using keys handled by AWS\n",
        "    * *SSE-KMS*: Use AWS Key Management Service to manage encryption keys\n",
        "      * Additional security (you must have access to KMS key)\n",
        "      * Audit trail for KMS key usage\n",
        "    * *SSE-C*: when you want to manage your own encryption keys\n",
        "    * *Client Side Encryption*\n",
        "  * From an ML perspective, *SSE-S3* and *SSE-KMS* will be most likely used\n",
        "  * S3 Security:\n",
        "    * *User Based*:\n",
        "      * IAM policies - which API calls should be allowed for a specific user\n",
        "    * *Resource Based*:\n",
        "      * Bucket Policies - bucket wide rules from the S3 console - allow cross account\n",
        "      * Object Access Control List (ACL) - finer grain\n",
        "      * Bucket Access Control List (ACL) - less common\n",
        "  * S3 Bucket Policies\n",
        "    * JSON based policies\n",
        "      * Resources: buckets and objects\n",
        "      * Actions: Set of API to Allow or Deny\n",
        "      * Effect: Allow/Deny\n",
        "      * Principal: the account or user to apply the policy to\n",
        "    * Use S3 bucket for policy to:\n",
        "      * Grant public access to the bucket\n",
        "      * Force objects to be encrypted at upload   \n",
        "      * Grant access to another account (Cross Account)\n",
        "  * The old way to enable default encryption was to use a bucket policy, the new way is to use the defualt encryption option in S3\n",
        "  * Other security types:\n",
        "    * Networking - **VPC Endpoint Gateway**\n",
        "      * Allow traffic to stay within your VPC (instead of public web)\n",
        "      * Make sure your private services (AWS SageMaker) can access S3\n",
        "      * Very important for AWS ML Exam\n",
        "    * Logging and Audit\n",
        "      * S3 access logs can be stored in other S3 bucket\n",
        "      * API calls can be logged in AWS CloudTrail\n",
        "    * Tagged Based (combined IAM policies and bucket policies)\n",
        "      * Example: Add tag Classification = PHI to your object   \n",
        "\n",
        "<br>\n",
        "\n",
        "**KINESIS**\n",
        "* *Kinesis* is a managed alternative to Apache Kafka\n",
        "* Great for app logs, metrics, IoT, **real time** big data and streaming processing framworks (Spark, NiFi)\n",
        "* Data is automatically replicated synchronously to 3 AZ\n",
        "* **Kinesis Stream**: low latency streaming ingest at scale\n",
        "  * Streams are divided in ordered Shards\n",
        "  * Data retention is 24h by default, can go up to 365 days\n",
        "  * Multiple apps can consume the same streams\n",
        "  * Once data is inserted in Kinesis, it can't be deleted\n",
        "  * Records can be up to 1MB in size\n",
        "  * Capacity Modes:\n",
        "    * Provisioned Mode:\n",
        "      * You choose the number of shards provisioned, scale manually or using API\n",
        "      * Each shard gets 1MB in (1000 records per second)\n",
        "      * Each shard gets 2MB out\n",
        "      * You pay per shard provisioned per hour\n",
        "    * On Demand Mode:\n",
        "      * No need to provision or manage the capacity\n",
        "      * Default capacity provisioned (4MB per second)\n",
        "      * Scales automatically based on observed throughput peak during the last 30 days\n",
        "      * Pay per stream per hour & data in/out per GB\n",
        "  * Limits:\n",
        "    * Producer:\n",
        "      * 1MB or 1000 messages at write per shard\n",
        "      * \"ProvisionedThroughputException\" otherwise\n",
        "    * Consumer:\n",
        "      * 2MB at read per shard across all consumers\n",
        "      * 5 API calls per second per shard across all consumers\n",
        "    * Data Retention:\n",
        "      * 24 hours data retention by default\n",
        "      * Can be extended to 365 days\n",
        "  * RECAP:\n",
        "    * Going to write custom code (producer/consumer)\n",
        "    * Real Time (200ms latency for classic, 70ms latency for enhanced fan-out)\n",
        "    * Automatic scaling with On-Demand Mode\n",
        "    * Data Storage for 1 to 365 days, replay capability, multi consumers     \n",
        "* **Kinesis Firehose**: load streams into S3, Redshift, ElasticSearch & Splunk\n",
        "  * Fully managed service, no administration\n",
        "  * Near real time (60 sec latency minimum for non full batches)\n",
        "  * Automatic scaling\n",
        "  * Supports many data formats\n",
        "  * Data conversion from CSV/JSON to Parquet/ORC (only for S3)\n",
        "  * Data transformation through AWS Lambda\n",
        "  * Supports compression when target is S3 (ZIP, SNAPPY)\n",
        "  * Pay for the amount of data going through Firehose  \n",
        "  * RECAP:\n",
        "    * Fully managed, send to S3, Splunk, Redshift, ElasticSearch\n",
        "    * Serverless data transformation with Lambda\n",
        "    * Near real time (lowest buffer time is 1 minute)\n",
        "    * Automated scaling \n",
        "    * No data storage            \n",
        "* **Kinesis Analytics**: perform real-time analytics on streams using SQL\n",
        "  * Use cases:\n",
        "    * *Streaming ETL*: select columns, make simple transformation on streaming data\n",
        "    * *Continuous metric generation*: live leaderboard for a mobile game\n",
        "    * *Responsive analytics*: look for certain criteria and build alerting\n",
        "  * Features:\n",
        "    * Pay only for resources consumed (not cheap)\n",
        "    * Serverless, scales automatically\n",
        "    * Use IAM permission to access streaming source and destination\n",
        "    * SQL or Flink to write the computation\n",
        "    * Schema discovery\n",
        "    * Lambda for preprocessing\n",
        "  * ML on Kinesis Data Analytics:\n",
        "    * *RANDOM_CUT_FOREST*\n",
        "      * SQL function for **anomaly detection** on numeric columns in a stream\n",
        "      * Use **recent history** to compute model\n",
        "    * *HOTSPOTS*\n",
        "      * Locate and return info about relatively dense regions in your data      \n",
        "* **Kinesis Video Streams**: meant for streaming video in real-time\n",
        "  * Producers:\n",
        "    * Security camera, body worn camera, AWS DeepLens, smartphone camera, radar data\n",
        "    * One producer per video stream\n",
        "  * Video playback capability\n",
        "  * Consumers:\n",
        "    * Build your own (MXNet, Tensorflow)\n",
        "    * AWS SageMaker\n",
        "    * AWS Rekognition Video\n",
        "  * Keep data for 1 hour to 10 years\n",
        "\n",
        "<br>\n",
        "\n",
        "* **Kinesis Summary - ML**\n",
        "  * *Kinesis Data Stream*: Create real-time ML applications\n",
        "  * *Kinesis Data Firehose*: Ingest massive data near-real time, e.g. put it into S3, and then perform some training into an algorithm to train ML models\n",
        "  * *Kinesis Data Analytics*: Real-time ETL/ML algorithms on streams or real-time ML algorithm as Random_Cut_Forest on streams data \n",
        "  * *Kinesis Video Streams*: Real-time video stream to create ML applications (face detection)\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS GLUE**\n",
        "* **Glue Data Catalog**\n",
        "  * Metadata repository for all your tables\n",
        "    * Automated schema inference\n",
        "    * Schemas are versioned\n",
        "  * Integrates with Athena or Redshift Spectrum (schema & data discovery) \n",
        "* **Glue Crawlers**: can help build the Glue Data Catalog\n",
        "  * Crawlers go through your data to infer schemas and partitions \n",
        "  * Works JSON, Parquet, CSV, relational store\n",
        "  * Crawlers work for S3, Redshift, RDS\n",
        "  * Run the crawler on a schedule or on demand\n",
        "  * Need an IAM role/credentials to access the data stores \n",
        "* **Glue & S3 Partitions**:\n",
        "  * Glue crawler will extract partitions based on how your S3 data is organized\n",
        "  * Think up front about how you will be querying your data lake in S3\n",
        "  * Do you query primarily by *time ranges* ?\n",
        "    * Organize your buckets as s3://my-bucket/dataset/yyyy/mm/dd/device\n",
        "  * Do you query primarily by *device* ?\n",
        "    * Organize your buckets as s3://my-bucket/dataset/device/yyyy/mm/dd \n",
        "* **Glue ETL**\n",
        "    * Transform data, clean data, enrich data (before analysis)\n",
        "      * Generate ETL code in Python or Scala, you can modify the code\n",
        "      * Can provide your own Spark or PySpark scripts\n",
        "      * Target can be S3, JBDC (RDS, Redshift) or Glue Data Catalog\n",
        "    * Fully managed, cost effective, pay only for resource consumed\n",
        "    * Jobs are run on serverless Spark platform\n",
        "    * *Glue Scheduler*: schedule the jobs\n",
        "    * *Glue Triggers*: automate job runs based on events\n",
        "    * **Transformation**\n",
        "      * *Bundled Transformation*\n",
        "        * DropFields, DropNullFields - remove null fields\n",
        "        * Filter - specify a function to filter records\n",
        "        * Join - to enrich data\n",
        "        * Map - add fields, delete fields\n",
        "      * *ML Transformation*\n",
        "        * **FindMatches ML**: identify duplicate or matching records in your dataset, even when the records don't have a common unique identifier and no field match exactly\n",
        "      * *Format Conversion*: CSV, JSON, Avro, Parquet\n",
        "      * *Apache Spark Trasnformation*: e.g. K-Means\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS DATA STORES for ML**\n",
        "* *RedShift*\n",
        "  * Data Warehousing, SQL analytics (OLAP - Online Analytical Processing)\n",
        "  * OLAP -> columnar based (data is organized in columns)\n",
        "  * Load data from S3 to Redshift\n",
        "  * Use Redshift Spectrum to query data directly in S3 (no loading)\n",
        "* *RDS, Aurora*\n",
        "  * Relational Store, SQL (OLTP - Online Transaction Processing)\n",
        "  * OLTP -> row based (data is organized in rows)\n",
        "  * Must provision servers in advance\n",
        "* *DynamoDB*\n",
        "  * NoSQL data store, serverless, provision read/write capacity\n",
        "  * Useful to store a machine learning model server by your application\n",
        "* *S3*\n",
        "  * Object storage\n",
        "  * Serverless, infinite storage\n",
        "  * Integration with most AWS Services\n",
        "* *OpenSearch (ElasticSearch)*\n",
        "  * Indexing of data\n",
        "  * Search amongst data points\n",
        "  * Clickstream analytics\n",
        "* *ElastiCache*\n",
        "  * Caching mechanism\n",
        "  * Not really used for ML\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS DATA PIPELINE**\n",
        "* Destination include S3, RDS, DynamoDB, Redshift and EMR\n",
        "* Manages task dependencies\n",
        "* Retries and notifies on failures\n",
        "* Data sources may be on-premises\n",
        "* Highly available\n",
        "* *Data Pipeline vs Glue*\n",
        "  * **Glue**\n",
        "    * Glue ETL - run Apache Spark code, Scala or Python based, focus on the ETL\n",
        "    * Glue ETL - don't worry about configuring or managing the resources\n",
        "    * Data Catalog to make the data available to Athena or Redshift Spectrum\n",
        "  * **Data Pipeline**\n",
        "    * Orchestration service\n",
        "    * More control over the environment, compute resources that run code \n",
        "    * Allows access to EC2 or EMR instances (creates resources in your own account)\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS BATCH**\n",
        "* Run batch jobs as Docker Images \n",
        "* Dynamic provisioning of the instances (EC2 & Spot Instances)\n",
        "* Optimal quantity and type based on volume and requirements \n",
        "* No need to manage clusters, fully serverless\n",
        "* You just pay for the underlying EC2 instances\n",
        "* Schedule Batch jobs using CloudWatch Events\n",
        "* Orchestrate Batch Jobs using AWS Step Function\n",
        "* *Batch vs Glue*\n",
        "  * **Glue**\n",
        "    * Glue ETL - run Apache Spark code, Scala or Python based, focus on the ETL\n",
        "    * Glue ETL - don't worry about configuring or managing the resources\n",
        "    * Data Catalog to make the data available to Athena or Redshift Spectrum\n",
        "  * **Batch**\n",
        "    * For any computing job regardless of the job (must provide Docker image)\n",
        "    * Resources are created in your account, managed by Batch\n",
        "    * For any non-ETL related work, Batch is probably better\n",
        "\n",
        "<br>\n",
        "\n",
        "**DMS - DATABASE MIGRATION SERVICE**\n",
        "* Quickly and securely migrate databases to AWS, resilient, self healing\n",
        "* The source db remains available during the migration\n",
        "* Supports:\n",
        "  * Homogeneous migrations: ex Oracle to Oracle\n",
        "  * Heterogeneous migrations: ex Microsoft SQL to Aurora\n",
        "* Continuous Data Replication using CDC\n",
        "* You must create an EC2 instance to perform the replication tasks\n",
        "* *AWS DMS vs Glue*\n",
        "  * **Glue**\n",
        "    * Glue ETL - run Apache Spark code, Scala or Python based, focus on the ETL\n",
        "    * Glue ETL - don't worry about configuring or managing the resources\n",
        "    * Data Catalog to make the data available to Athena or Redshift Spectrum\n",
        "  * **AWS DMS**\n",
        "    * Continuous Data Replication\n",
        "    * No data transformation\n",
        "    * Once the data is in AWS, you can use Glue to transform it\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS STEP FUNCTION**\n",
        "* Use to orchestrate and design workflows\n",
        "* Easy visualizations\n",
        "* Advanced Error Handling and Retry mechanism outside the code\n",
        "* Audit of the history of workflows\n",
        "* Ability to wait for an arbitrary amount of time\n",
        "* Max execution time of a State Machine is 1 year\n",
        "* *!! EXAM TIP !!*: Anytime you need to orchestrate some things, or make sure some thing happens and another thing happens then Step Function are the perfect candidate for this\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS DATASYNC**\n",
        "* For data migrations from on-premises to AWS storage services\n",
        "* A DataSync Agent is deployed as a VM and connects to your internal storage \n",
        "  * NFS, SMB, HDFS\n",
        "* Encryption and data validation\n",
        "\n",
        "<br>\n",
        "\n",
        "**MQTT**\n",
        "* An Internet of Things (IoT) thing\n",
        "* Standard messaging protocol\n",
        "* Think of it as how lots of sensor data might get transferred to your ML model\n",
        "* The AWS IoT Device SDK can connect via MQTT\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gBRL5BaZvtzC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. EXPLORATORY DATA ANALYSIS"
      ],
      "metadata": {
        "id": "KMoZNBhhA122"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TYPES OF DATA**\n",
        "* **Numerical**\n",
        "  * Represent some sort of quantitative measurement (heights of people, page load times, stock prices, etc)\n",
        "  * *Discrete data*: Integer based\n",
        "  * *Continuous data*: Infinite number of possible values\n",
        "* **Categorical**\n",
        "  * Qualitative data that has no inherent mathematical meaning (gender, yes/no, state of residence, etc)\n",
        "  * You can assign numbers to categories in order to represent them more compactly, but the numbers don't have mathematical meaning\n",
        "* **Ordinal**\n",
        "  * A mixture of numerical and categorical\n",
        "  * Categorical data that has mathematical meaning \n",
        "  * Example: movie ratings on a 1-5 scale\n",
        "\n",
        "<br>\n",
        "\n",
        "**DATA DISTRIBUTION**\n",
        "* **Normal/Gaussian Distribution**\n",
        "  * Gives you the probability of a data point falling within some given range of a given value\n",
        "* **Probability Mass Function**\n",
        "  * The way that we visualize the probability of discrete data occuring \n",
        "* **Poisson Distribution**\n",
        "  * Example of probability mass function\n",
        "  * It deals with discrete data\n",
        "* **Binomial Distribution**\n",
        "  * This just describe the number of successes in a sequence of experiments with a yes/no questions    \n",
        "* **Bernoulli Distribution**\n",
        "  * Special case of Binomial Distribution\n",
        "  * Has a single trial (n=1)\n",
        "  * Can think of a binomial distribution as the sum of Bernoulli distribution\n",
        "\n",
        "<br>\n",
        "\n",
        "**TIME SERIES ANALYSIS**\n",
        "* **Trends**\n",
        "  * When a time series seem to be trending in one direction\n",
        "* **Seasonality**\n",
        "  * The time series tends to peak during certain intervals in a cyclical way\n",
        "* **Noise**\n",
        "  * Some variations are just random in nature\n",
        "  * Seasonality + Trends + Noise = Time Series\n",
        "    * Additive model\n",
        "    * Seasonal variation is constant\n",
        "  * Sometimes Seasonality \\* Trends \\* Noise - Trends, sometimes amplify Seasonality and Noise\n",
        "  * Seasonal variation increases as the trend increases\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS ATHENA**\n",
        "* **What is?**\n",
        "  * Interactive query service for S3 (SQL)\n",
        "  * No need to load data, it stays in S3\n",
        "  * Presto under the hood\n",
        "  * Serverless\n",
        "  * Supports many data formats (CSV, JSON, ORC, Parquet, Avro)\n",
        "  * Unstructured, semi-structured or structured\n",
        "* **Examples**\n",
        "  * Ad-hoc queries of web logs\n",
        "  * Querying staging data before loading to Redshift\n",
        "  * Analyze CloudTrail/CloudFront/VPC/ELB logs in S3\n",
        "  * Integration with Jupyter, Zeppelin, RStudio notebooks\n",
        "  * Integration with QuickSight\n",
        "  * Integration via ODBC/JDBC with other visualization tools\n",
        "* **Cost Model**\n",
        "  * Pay as you go\n",
        "    * $5 per TB scanned\n",
        "    * Successful or cancelled queries count, failed queries don't\n",
        "    * No charge for DDL (CREATE, ALTER, DROP, etc)\n",
        "  * Save lots of money by using columnar formats\n",
        "    * ORC, Parquet\n",
        "    * Save 30%-90% and get better performance\n",
        "  * Glue and S3 have their own charges\n",
        "* **Security**\n",
        "  * Access control\n",
        "    * IAM, ACLs, S3 bucket policies\n",
        "    * AmazonAthenaFullAccess / AWSQuickSightAthenaAccess\n",
        "  * Encrypt results at rest in S3 staging directory\n",
        "    * Server-side encryption with S3 managed key (SSE-S3)\n",
        "    * Server-side encryption with KMS key (SSE-KMS)     \n",
        "    * Client-side encryption with KMS key (CSE-KMS)  \n",
        "  * Cross-account access in S3 bucket policy possible\n",
        "  * Transport Layer Security (TLS) encrypts in-transit (between Athena and S3) \n",
        "* **Anti Patterns**\n",
        "  * Highly formatted reports/visualization\n",
        "    * That's what QuickSight is for\n",
        "  * ETL\n",
        "    * Use Glue instead\n",
        "\n",
        "<br>\n",
        "\n",
        "**AWS QUICKSIGHT**\n",
        "* **What is QuickSight?**\n",
        "  * Business analytics and visualizations in the cloud\n",
        "  * Fast, easy, cloud-powered business analytics service\n",
        "  * Allows all employees in an organization to:\n",
        "    * Build visualization\n",
        "    * Perform ad-hoc analysis\n",
        "    * Quickly get business insights from data\n",
        "    * Anytime, on any device (browsers, mobile)\n",
        "  * Serverless\n",
        "* **Quicksight Data Sources**\n",
        "  * Redshift\n",
        "  * Aurora/RDS\n",
        "  * Athena\n",
        "  * EC2-hosted databases\n",
        "  * Files (S3 or on-premises)\n",
        "    * Excel\n",
        "    * CSV, TSV\n",
        "    * Common or extended log format \n",
        "  * Data preparation allows limited ETL\n",
        "* **Spice**\n",
        "  * Data sets are imported into Spice\n",
        "    * Super fast, parallel, in-memory calculation engine\n",
        "    * Uses columnar storage, in-memory, machine code generation\n",
        "    * Accelerates interactive queries on large datasets\n",
        "  * Each user gets 10GB of Spice\n",
        "  * Highly available / durable\n",
        "  * Scales to hundreds of thousands of users\n",
        "* **QuickSight Use Cases**\n",
        "  * Interactive ad-hoc exploration / visualization of data\n",
        "  * Dashboard and KPI's\n",
        "  * Analyze / visualize data from:\n",
        "    * Logs in S3\n",
        "    * On-premises databases\n",
        "    * AWS (RDS, Redshift, Athena, S3)\n",
        "    * SaaS applications such as Salesforce\n",
        "    * Any JDBC/ODBC data source\n",
        "* **ML Insights**\n",
        "  * Anomaly Detection\n",
        "  * Forecasting\n",
        "  * Auto-narratives\n",
        "* **QuickSight Anti-Patterns**\n",
        "  * Highly formatted canned reports\n",
        "    * QuickSight is for ad-hoc queries, analysis and visualization\n",
        "  * ETL\n",
        "    * Use Glue instead, although QuickSight can do some transformations\n",
        "* **QuickSight Security**\n",
        "  * Multi factor authentication on your account\n",
        "  * VPC connectivity\n",
        "    * Add QuickSight's IP address range to your database security groups\n",
        "  * Row level security\n",
        "  * Private VPC access\n",
        "    * Elastic Network Interface\n",
        "    * AWS Direct Connect  \n",
        "* **QuickSight User Management**  \n",
        "  * Users defined via IAM or email signup\n",
        "  * Active Directory integration with QuickSight Enterprise Edition\n",
        "* **QuickSight Pricing** \n",
        "  * Annual Subscription\n",
        "    * Standard: $9/user/month   \n",
        "    * Enterprise: $18/user/month\n",
        "  * Extra SPICE capacity (beyond 10GB)\n",
        "    * $0.25 (standard) - $0.38 (enterprise)/GB/month \n",
        "  * Month to month\n",
        "    * Standard: $12/GB/month\n",
        "    * Enterprise: $24/GB/month\n",
        "  * Enterprise edition\n",
        "    * Encryption at rest\n",
        "    * Microsoft Active Directory integration\n",
        "* **QuickSight Visualization**\n",
        "  * Visual Types:\n",
        "    * *AutoGraph*: It automatically selects the most appropriate visualization based on the properties of the data itself\n",
        "    * *Bar Charts*: For comparison and distribution (histograms)\n",
        "    * *Line Graphs*: For changes over time\n",
        "    * *Scatter Plots, Heat Maps*: For correlation\n",
        "    * *Pie Graphs, Tree Maps*: For aggregation\n",
        "    * *Pivot Tables*: For tabular data, excel format\n",
        "\n",
        "<br>\n",
        "\n",
        "**EMR (Elastic MapReduce)**\n",
        "\n",
        "EMR provides a way of distributing the load of processing the data across an entire cluster of computers. So for massive datasets often you need a cluster to actually process that data and prepare it for your ML training jobs in parallel across an entire cluster\n",
        "* **What is EMR?**\n",
        "  * Managed Hadoop framework on EC2 instances\n",
        "  * Includes Spark, HBase, Presto, Flink, Hive and more\n",
        "  * EMR notebooks\n",
        "  * Several integration points with AWS\n",
        "* **EMR Cluster**\n",
        "  * *Master Node*:\n",
        "    * Manages the cluster\n",
        "    * Single EC2 instance\n",
        "  * *Core Node*:\n",
        "    * Hosts HDFS data and runs taks \n",
        "    * Can be scaled up & down but with some risk\n",
        "  * *Task Node*:\n",
        "    * Runs tasks, doesn't host data\n",
        "    * No risk of data loss when removing\n",
        "    * Good use of spot instances\n",
        "* **EMR Usage**\n",
        "  * Transient vs Log-Running Clusters\n",
        "    * *Transient*:\n",
        "      * It's configured to be automatically termined once all the steps you've defined have been completed (e.g.loading data, processing data, storing output)\n",
        "      * If you have a predefined sequence that you want your cluster to do\n",
        "    * *Long-Running*:\n",
        "      * You want to interact with the application directly and then just manually terminate it\n",
        "      * Appropriate for experimenting with datasets  \n",
        "    * Can spin up task nodes using Spot Instances for temporary capacity\n",
        "    * Can use reserved instances on long-running clusters to save $\n",
        "  * Connect directly to master to run jobs \n",
        "  * Submit ordered steps via the console\n",
        "  * EMR Serverless lets AWS scale your nodes automatically \n",
        "* **EMR / AWS Integration**\n",
        "  * EC2 for the instances that comprise the nodes in the cluster\n",
        "  * VPC to configure the virtual network in which you launch your instances\n",
        "  * S3 to store input and output data\n",
        "  * CloudWatch to monitor cluster performance and configure alarms\n",
        "  * IAM to configure permissions\n",
        "  * CloudTrail to audit requests made to the service\n",
        "  * Data Pipeline to schedule and start your cluster\n",
        "* **EMR Storage**\n",
        "  * HDFS\n",
        "  * EMRFS\n",
        "    * Access S3 as if it were HDFS\n",
        "    * EMRFS Consistent View - optional for S3 consistency\n",
        "    * Local file system\n",
        "    * EBS for HDFS\n",
        "* **EMR Promises**\n",
        "  * EMR charges by the hour + EC2 charges\n",
        "  * Provisions new nodes if a core node fails\n",
        "  * Can add and remove tasks nodes on the fly\n",
        "  * Can resize a running cluster's core nodes\n",
        "* **Hadoop** \n",
        "  * It's composed of:\n",
        "    * *HDFS*:\n",
        "      * It's the base, Hadoop File System, a distributed file system for Hadoop \n",
        "      * It distributes the data and stores across the instances in the cluster\n",
        "      * Multiple copies of the data are stored on different instances to ensure no data is lost if an individual instance fails\n",
        "    * *YARN*:\n",
        "      * It's on top of HDFS\n",
        "      * YARN (Yet Another Resource Negotiator)\n",
        "      * It centrally manages cluster resources from multiple data processing frameworks\n",
        "    * *MapReduce*:\n",
        "      * It's a software framework for easily writing applications that process vast amounts of data in parallel on large clusters of commodity hardware in a reliable fall tolerant manner\n",
        "* **Spark**\n",
        "  * It's an open source distrubuted processing system commonly used for big data workloads and it's better than MapReduce\n",
        "  * It utilizes in memory cachin, optimizes query execution for fast analytic queries against data of any size\n",
        "  * It has API for Python, Java, Scala and R\n",
        "  * Use cases: \n",
        "    * Stream Processing\n",
        "    * Interactive SQL\n",
        "    * ML\n",
        "  * Spark components:\n",
        "    * *Spark Core*: the foundation of the platform, it's responsible for things like memory management, fault recovery, scheduling, distributing and interacting with storage systems\n",
        "    * *Spark SQL*: Distributed query engine that provides low latency interactive queries up to 100 times faster than MapReduce. Columnar storage and code generation for fast queries and it supports various data sources (JBDC, ODBC, JSON, HDFS, Hive, ORC and Parquet). It exposes dataframes in Python\n",
        "    * *Spark Streaming*: streaming analytics, data gets ingested in mini batches and it can be integrated with AWS Kinesis\n",
        "    * *MLLib*: ML library for Spark\n",
        "      * Classification: Logistic Regression, Naive Bayes\n",
        "      * Regression\n",
        "      * Decision Tree\n",
        "      * Recommendation engine (ALS)\n",
        "      * Clustering (K-Means)\n",
        "      * LDA (topic modeling)\n",
        "      * ML workflow utilities (pipelines, feature transformation, persistence)\n",
        "      * SVD, PCA, statistics\n",
        "    * *GraphX*: distributed graph processing framework \n",
        "  * Zeppelin + Spark\n",
        "    * Can run Spark code interactively (like in Spark shell)\n",
        "      * This speeds up your development cycle\n",
        "      * Allows easy experimentation and exploration of your big data\n",
        "    * Can execute SQL queries directly against SparkSQL\n",
        "    * Query results may be visualized in charts and graphs\n",
        "    * Makes Spark feel more like a data science tool\n",
        "* **EMR Notebook**\n",
        "  * Similar concept to Zeppelin, with more AWS integration\n",
        "  * Notebooks backed up to S3\n",
        "  * Provision clusters from the notebook\n",
        "  * Hosted inside a VPC\n",
        "  * Accessed only via AWS console\n",
        "* **EMR Security**\n",
        "  * IAM policies\n",
        "  * Kerberos\n",
        "  * SSH\n",
        "  * IAM roles\n",
        "* **EMR Instance Types**\n",
        "  * *Master node*:\n",
        "    * m4.large if < 50 nodes  \n",
        "    * m4.xlarge if > 50 nodes\n",
        "  * *Core & task nodes*:\n",
        "    * m4.large is usually good\n",
        "    * If cluster waits a lot in external dependencies: t2.medium\n",
        "    * Improved performance: m4.xlarge\n",
        "    * Computation-intensive applications: high CPU instances\n",
        "    * Database, memory-caching applications: high memory instances\n",
        "    * Network/CPU intensive (NLP, ML): cluster computer instances\n",
        "  * *Spot instances*:\n",
        "    * Good choice for task nodes\n",
        "    * Only use on core & master if you're testing or very cost-sensitive; you're risking partial data loss\n",
        "\n",
        "<br>\n",
        "\n",
        "**FEATURE ENGINEERING**\n",
        "* **What is Feaure Engineering?**\n",
        "  * Applying your knowledge of the data (and the model you are using) to create better features to train your model with\n",
        "    * Which features should I use?\n",
        "    * Do I need to transform these features in some way?\n",
        "    * How do I handle missing data?\n",
        "    * Should I create new features from the existing ones?\n",
        "  * You can't just throw in raw data and expect good results\n",
        "  * This is the art of ML, where expertise is applied\n",
        "  * \"Applied ML is basically feature engineering\" - Andrew Ng\n",
        "* **The Curse of Dimensionality**\n",
        "  * Too many features can be a problem - leads to sparse data\n",
        "  * As we keep adding more and more dimensions, the available space that we have to work with just keeps exploding\n",
        "  * More features you have, the larger the space that we can find a solution is within\n",
        "  * Every feature is a new dimension\n",
        "  * Much of feature engineering is selecting the features most relevant to the problem at hand\n",
        "    * This often is where domain knowledge comes into play\n",
        "  * Unsupervised dimesnionality reduction techniques can also be employed to distill many features into fewer features \n",
        "    * PCA\n",
        "    * K-Means\n",
        "* **Imputing Missing Data**\n",
        "  * **Mean Replacement**\n",
        "    * Replace missing values with the mean value from the rest of the column\n",
        "    * Fast & easy, won't affect mean or sample size of overall data set\n",
        "    * Median may be a better choice than mean when outliers are present\n",
        "    * But it's generally pretty terrible:\n",
        "      * Only works on column level, misses correlations between features\n",
        "      * Can't use on categorical features\n",
        "      * Not very accurate\n",
        "  * **Dropping**\n",
        "    * If not many rows contains missing data\n",
        "      * and dropping those rows doesn't bias your data ...\n",
        "      * and you don't have a lot of time ...\n",
        "      * maybe it's a reasonable thing to do\n",
        "    * But it's never going to be the right answer for the best approach\n",
        "    * Almost anything is better\n",
        "  * **Machine Learning**\n",
        "    * **KNN**: Find K nearest (most similar) rows and average their values\n",
        "      * Assumes numerical data, not categorical\n",
        "      * These are ways to handle categorical data, but categorical data is probably better served by DL\n",
        "    * **Deep Learning**\n",
        "      * Build a ML model to impute data for your ML model\n",
        "      * Works well for categorical data. Really well. But it's complicated\n",
        "    * **Regression**\n",
        "      * Find linear or non-linear relationship between the missing feature and other features\n",
        "      * Most advanced technique: MICE (Multiple Imputation by Chained Equations)\n",
        "  * **Just get more data**\n",
        "    * What's better than imputing data? Getting more real data\n",
        "    * Sometimes you just have to try harder or collect more data\n",
        "\n",
        "<br>\n",
        "\n",
        "**HANDLING UNBALANCED DATA**\n",
        "* **What is Unbalanced Data?**\n",
        "  * Large discrepancy between \"positive\" and \"negative\" cases:\n",
        "    * Fraud detection: fraud is rare and most rows will be not-fraud\n",
        "    * Don't let the terminology confuse you: positive doesn't mean \"good\":\n",
        "      * It means the thing you're testing for is what happened\n",
        "      * If your ML model is made to detect fraud, then fraud is the positive case\n",
        "  * Mainly a problem with NN\n",
        "* **Oversampling**\n",
        "  * Duplicate samples from the minority class\n",
        "  * Can be done at random\n",
        "* **Undersampling** \n",
        "  * Instead of creating more positive samples, remove negatives ones\n",
        "  * Throwing data away is usually not the right answer\n",
        "    * Unless you are specifically trying to avoid big data scaling issue\n",
        "* **SMOTE**\n",
        "  * Synthetic Minority Over-Sampling Technique\n",
        "  * Artificially generate new samples of the minority class using nearest neighbors\n",
        "    * Run K-nearest-neighbors of each sample of the minority class \n",
        "    * Create a new sample from the KNN result (mean of the neighbors)\n",
        "  * Both generates new samples and undersamples majority class\n",
        "  * Generally better than just oversampling\n",
        "* **Adjusting Thresholds**\n",
        "  * When making predictions about a classification (fraud/not fraud) you have some sort of threshold of probability at which point you'll flag something as the positive case (fraud)\n",
        "  * If you have too many false positive, one way to fix that is to simply increase that threshold\n",
        "    * Guaranteed to reduce false positive\n",
        "    * But could result in more false negatives\n",
        "\n",
        "<br>\n",
        "\n",
        "**HANDLING OUTLIERS**\n",
        "* **Variance** \n",
        "  * Variance ($σ^2$) is simply the average of the squared differences from the mean\n",
        "  * $σ^2 = \\frac{\\sum (x-μ)^2}{N}$\n",
        "    * *x*: the example\n",
        "    * *μ*: the average value\n",
        "    * *N*: the total number of values\n",
        "  * Square is applied for 2 reasons:\n",
        "    * We want negative variance to count just as much as positive variance\n",
        "    * Also we want to give more weight to the outliers, so this amplifies the effect of the values very different from the mean\n",
        "* **Standard Deviation**\n",
        "  * Standard Deviation ($σ$) is just the square root of the Variance\n",
        "  * This is usually used as a way to identify outliers\n",
        "  * Data points that lie more than one standard deviation from the mean can be considered unusual\n",
        "  * You can talk about how extreme a data point is by talking about \"how many sigmas\" away from the mean it is\n",
        "* **Dealing with Outliers**\n",
        "  * Sometimes it's appropriate to remove outliers from your training data\n",
        "  * Do this responsably, understand why you are doing this\n",
        "  * For example: in collaborative filtering, a single user who rates thousands of movies could have a big effect on everyone else's rating. That may not be desirable\n",
        "  * Another example: in web log data, outliers may represent bots or other agents that should be discarded\n",
        "  * But if someone really wants the mean income of US citizen for example, don't toss out billionaires just because you want to\n",
        "  * Our old friend standard deviation provides a principled way to classify outliers\n",
        "  * Find data points more than some multiple of a standard deviation in your training data\n",
        "  * What multiple? You just have to use common sense\n",
        "  * Remember AWS's Random Cut Forest algorithm creeps into many of its services - it's made for outlier detection\n",
        "    * Found within QuickSight, Kinesis Analytics, SageMaker and more\n",
        "* **Binning**\n",
        "  * Bucket observations together based on ranges of values \n",
        "  * Example: estimated ages of people\n",
        "    * Put all 20-somethings in one classification, 30-something in another, etc\n",
        "  * Quantile binnning categorizes data by their place in the data distribution\n",
        "    * Ensures even sizes of bins\n",
        "  * Transforms numeric data to ordinal data\n",
        "  * Especially useful when there is uncertainty in the measurements\n",
        "* **Transforming**\n",
        "  * Applying some function to a feature to make it better suited for training\n",
        "  * Feature data with an exponential trend may benefit from a logarithmic transform\n",
        "* **Encoding**\n",
        "  * Transforming data into some new representation required by the model\n",
        "  * **One-hot encoding**\n",
        "    * Create buckets for every category\n",
        "    * The bucket for your category has a 1, all others have a 0\n",
        "    * Very common in Deep Learning where categories are represented by individual output neurons\n",
        "* **Scaling/Normalization**\n",
        "  * Some models prefer feature data to be normally distributed around 0 (most NN)\n",
        "  * Most models require feature data to at least be scaled to comparable values\n",
        "    * Otherwise features with larger magnitudes will have more weight than they should\n",
        "    * Example: modeling age and income as features - incomes will be much higher values than ages\n",
        "  * Scikit_learn has a preprocessor module that helps (MinMaxScaler, etc)\n",
        "  * Remember to scale your results back up\n",
        "* **Shuffling**\n",
        "  * Many algorithms benefit from shuffling their training data\n",
        "  * Otherwise they may learn from residual signals in the training data resulting from the order in which they were collected\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER GROUND TRUTH**\n",
        "* **What is Ground Truth?**\n",
        "  * Sometimes you don't have training data at all, and it needs to be generated by human first\n",
        "  * Example: training an image classification model. Somebody needs to tag a bunch of images with what they are images of before training a neural network\n",
        "  * Ground Truth manages humans who will label your data for training purpose\n",
        "  * Ground Truth creates its own model as images are labeled by people\n",
        "  * As this model learns, only images the model isn't sure about are sent to human labelers\n",
        "  * This can reduce the cost of labeling jobs by 70%\n",
        "  * Who are these himan labelers?\n",
        "    * AWS Mechanical Turk\n",
        "    * Your own internal team\n",
        "    * Professional labeling companies\n",
        "* **Ground Truth Plus**\n",
        "  * Turnkey solution\n",
        "  * \"Our team of AWS Experts\" manages the workflow and team of labelers\n",
        "    * You fill out an intake form\n",
        "    * They contact you and discuss pricing\n",
        "  * You track progress via the Ground Truth Plus Project Portal\n",
        "  * Get labeled data from S3 when done\n",
        "* **Other Ways to Generate Training Labels**\n",
        "  * *Rekognition*\n",
        "    * AWS service for image recognition\n",
        "    * Automatically classify images\n",
        "  * *Comprehend*\n",
        "    * AWS service for text analysis and topic modeling\n",
        "    * Automatically classify text by topics, sentiment\n",
        "  * Any pre-trained model or unsupervised technique that may be helpful            \n",
        "\n"
      ],
      "metadata": {
        "id": "qNpI4R4aBBIA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. DEEP LEARNING"
      ],
      "metadata": {
        "id": "ZZy5sc-Wcfg2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTRO TO DEEP LEARNING**\n",
        "* **Biological Inspiration**\n",
        "  * Neurons in your cerebral cortex are connected via axons\n",
        "  * A neuron fires to the neuron it's connected to, when enough of its input signal are activated\n",
        "  * Very simple at the individual neuron level but layers of neuron connected in this way can yield learning behaviour\n",
        "  * Billions of neurons, each with thousands of connections, yields a mind\n",
        "  * Neurons in your cortex seem to be arranged into many stacks or **columns** that process information in parallel\n",
        "  * Mini-columns of around 100 neurons are organized into larger hyper-columns. There are 100 million mini-columns in your cortex\n",
        "  * This is coincidentally similar to how GPU's work\n",
        "* **How NN works?**\n",
        "  * It just sums up weighted inputs from the layer below and applies some sort of activation function to that weight and it passes the result up to the next layer\n",
        "  * The network is trained using data with known labels, with one-hot encoding, and during the training process it figures out the ideal weights between each neuron to get the right answer at the top\n",
        "* **Types of NNs**\n",
        "  * FeedForward Neural Network    \n",
        "  * **Convolutional Neural Network** (CNN)\n",
        "    * Image classification \n",
        "  * **Recurrent Neural Network** (RNN)\n",
        "    * Deals with sequences in time (predict stock prices, NLP, translation, etc)\n",
        "    * **LSTM** (Long Short Term Memory), **GRU** (Gated Recurrent Unit)\n",
        "* **NN frameworks**\n",
        "  * **TensorFLow**: a very popular choice, which is made by Google, and it also incorporates a higher level API called **Keras** \n",
        "  * **MXNet**: alternative to TensorFlow, it's made by Apache and maybe for that reason Amazon tends to gravitate toward MXNet more than TensorFlow\n",
        "\n",
        "<br>\n",
        "\n",
        "**ACTIVATION FUNCTIONS**\n",
        "* **What are and types**\n",
        "  * It's the function inside a given node/neuron that sums up all of the incoming inputs into that neuron and decides what output it should then send out to the next layer of neuron. \n",
        "  * **Linear or Identity Function**\n",
        "    * It doesn't really do anything\n",
        "    * Can't do backpropagation (no learning)\n",
        "  * **Binary Step Function**\n",
        "    * It's on or off\n",
        "    * Can't handle multiple classification - it's binary after all\n",
        "    * Vertical slopes don't work well with calculus (infinite derivative , the math blow up)\n",
        "  * Instead we need **Non-Linear Activation Functions**   \n",
        "    * These can create complex mappings between inputs and outputs\n",
        "    * Allow backpropagation (because they have a useful derivative)\n",
        "    * Allow for multiple layers (linear functions degenerate to a single layer)\n",
        "  * **Sigmoid Function (Logistic)**\n",
        "    * Nice & smooth \n",
        "    * Scales everything from 0 to 1\n",
        "    * Changes slowly for high of low values\n",
        "      * The *Vanishing Gradient Problem*\n",
        "    * Computationally expensive\n",
        "  * **Tanh Function**\n",
        "    * Nice & smooth \n",
        "    * Scales everything from -1 to 1\n",
        "    * Changes slowly for high of low values\n",
        "      * The *Vanishing Gradient Problem*\n",
        "    * Computationally expensive\n",
        "    * Tanh generally preferred over Sigmoid because when you are dealing with ML it's nice to have things with a mean around 0\n",
        "  * **Rectified Linear Unit (ReLU)**\n",
        "    * Very popular choice\n",
        "    * Easy and fast to compute\n",
        "    * But when inputs are 0 or negative we have a linear function and all of its problems\n",
        "      * The *Dying ReLu problem*\n",
        "  * **Leaky ReLU**\n",
        "    * Solves *Dying ReLU Problem* by introducing a negative slope below 0\n",
        "  * **Parametric ReLU (PReLU)**\n",
        "    * Leaky ReLU but the slope in the negative part is learned via backpropagation\n",
        "    * Complicated and YMMV\n",
        "  * **Other ReLU variants**\n",
        "    * **Exponential Linear Unit (ELU)\n",
        "    * **Swish**\n",
        "      * From Google, performs really well\n",
        "      * But it's not from Amazon...\n",
        "      * Mostly a benefit with very deep networks (40+ layers)\n",
        "    * **Maxout**\n",
        "      * Outputs the max of the inputs\n",
        "      * Technically ReLU is a special case of maxout\n",
        "      * But doubles parameters that need to be trained is not often practical\n",
        "  * **Softmax**\n",
        "    * Used on the final layer of a multiple classification problem\n",
        "    * Basically converts outputs to probabilities of each classification\n",
        "    * Can't produce more than one label for something (sigmoid can)          \n",
        "    * Don't worry about the actual function for the exam, just know what it's used for\n",
        "* **Choosing an activation function**\n",
        "  * For multiple classification use **softmax** on the output layer\n",
        "  * RNN's do well with **tanh**\n",
        "  * For everything else:\n",
        "    * Start with **ReLU**\n",
        "    * If you need to do better try **Leaky ReLU**\n",
        "    * Last resort: **PReLU**, **Maxout**\n",
        "    * **Swish** for really deep networks\n",
        "\n",
        "<br>\n",
        "\n",
        "**CONVOLUTIONAL NEURAL NETWORKS (CNN)**\n",
        "* **What are CNNs for?**\n",
        "  * When you look for some pattern or feature in your data but you don't know where exactly it might be\n",
        "    * Images that you want to find features within\n",
        "    * Machine translation\n",
        "    * Sentence Analysis\n",
        "    * Sentiment Analysis\n",
        "  * They can find features that aren't in a specific spot\n",
        "    * Like a stop sign in a picture\n",
        "    * Words within a sentence\n",
        "  * They are \"feature-location invariant\"\n",
        "* **How do CNNs work?**\n",
        "  * Inspired by the biology of the visual cortex\n",
        "    * Local receptive fields are groups of neurons that only respond to a part of what your eyes see (subsampling)\n",
        "    * They overlap each other to cover the entire visual field (convolutions)\n",
        "    * They feed into higher layers that identify increasingly complex images\n",
        "      * Some receptive fields identify horizontal lines, lines at different angles, etc (filters)\n",
        "      * These would feed into a layer that identifies shapes\n",
        "      * Which might feed into a layer that identifies objects\n",
        "    * For color images, extra layers for red, green and blue\n",
        "  * **CNN** is just taking a source image or a source data of any sort, breaking it up into little chunks called *convolutions* and then we assemble those and look for patterns at increasingly higher complexitiesin your NN\n",
        "* **How do we know that's a stop sign?**\n",
        "  * Individual local receptive fields scan the image looking for edges and pick up the edges of the stop sign in a layer\n",
        "  * Those edges in turn get picked up by a higher level convolutional that identifies the stop sign's shape (and letters)\n",
        "  * This shape then gets matched against your pattern of what a stop sign look like also using the strong red signal coming from your red layers\n",
        "  * That information keeps getting processed upward until your foot hits the brake\n",
        "  * A **CNN** works the same way\n",
        "* **CNNs with Keras/Tensorflow**\n",
        "  * Source data must be of appropriate dimensions\n",
        "    * width x length x color channels\n",
        "  * Conv2D layer type does the actual convolution on a 2D image \n",
        "    * Conv1D and Conv3D also available - doesn't have to be image data\n",
        "  * MaxPooling2D layers can be used to reduce a 2D layer down by taking the maximum value in a given block\n",
        "  * Flatten layers will convert the 2D layer to a 1D layer for passing into a flat hiden layer of neurons\n",
        "  * Typical usage:\n",
        "    1. Conv2D\n",
        "    2. MaxPooling2D\n",
        "    3. Dropout\n",
        "    4. Flatten\n",
        "    5. Dense\n",
        "    6. Dropout\n",
        "    7. Softmax\n",
        "* **CNNs are hard**\n",
        "  * Very resource-intensive (CPU, GPU and RAM)\n",
        "  * Lots of hyperparameters\n",
        "    * Kernel size, many layers with different numbers of units, amount of pooling... in addition to the usual stuff like number of layers, choice of optimizer\n",
        "  * Getting the training data is often the hardest part (as well as storing and accessing it)\n",
        "* **Specialized CNN Architectures**\n",
        "  * Defines specific arrangement of layers, padding and hyperparameters\n",
        "  * **LeNet-5**\n",
        "    * Good for handwritting recognition\n",
        "  * **AlexNet**\n",
        "    * Image classification, deeper than LeNet\n",
        "  * **GoogLeNet**\n",
        "    * Even deeper but with better performance\n",
        "    * Introduces *inception modules* (groups of convolutional layers)\n",
        "  * **ResNet (Residual Network)**\n",
        "    * Even deeper - maintains performance via skip connections\n",
        "\n",
        "<br>\n",
        "\n",
        "**RECURRENT NEURAL NETWORKS (RNN)**\n",
        "* **What are RNNs for?**\n",
        "  * Time-Series data\n",
        "    * When you want to predict future behaviour based on past behaviour\n",
        "    * Web logs, sensor logs, stock trades\n",
        "    * Where to drive your self-driving car based on past trajectories\n",
        "  * Data that consists of sequences of arbitrary length\n",
        "    * Machine Translation\n",
        "    * Image Captions\n",
        "    * Machine-Generated music\n",
        "* **RNN Topologies**\n",
        "  * *Sequence to Sequence*\n",
        "    * e.g. predict stock prices based on series of historical data\n",
        "  * *Sequence to Vector*\n",
        "    * e.g. words in a sentence to sentiment\n",
        "  * *Vector to Sequence* \n",
        "    * e.g. create captions from an image\n",
        "  * *Encoder -> Decoder*\n",
        "    * Sequence -> Vector -> Sequence\n",
        "    * e.g. machine translation\n",
        "* **Training RNNs**\n",
        "  * Backpropagation through time\n",
        "    * Just like backpropagation on MLP's but applied to each time step\n",
        "  * All those time steps add up fast\n",
        "    * Ends up looking like a really, really deep NN\n",
        "    * Can limit backpropagation to a limited number of time steps (truncated backpropagation through time)\n",
        "  * State from earlier time steps get diluted over time\n",
        "    * This can be a problem, for example when learning sentence structures\n",
        "    * If we're looking at words in a sentence, the words at the beginning of a sentence might be even more important than words toward the end\n",
        "  * **LSTM Cell**\n",
        "    * Long Short-Term Memory Cell\n",
        "    * Maintains separate short-term and long-term states\n",
        "  * **GRU Cell**\n",
        "    * Gated Recurrent Unit\n",
        "    * Simplified LSTM Cell that performs about as well\n",
        "  * Training is really hard:\n",
        "    * Very sensitive to topologies, choice of hyperparameters\n",
        "    * Very resource intensive\n",
        "    * A wrong choice can lead to a RNN that doesn't converge at all\n",
        "\n",
        "<br>\n",
        "\n",
        "**MODERN NLP WITH BERT AND GPT AND TRANSFER LEARNING**\n",
        "* **Modern NLP (Natural Language Processing)**\n",
        "  * **Transformer** deep learning architectures are what's hot\n",
        "    * Adopts mechanism of **self-attention**\n",
        "      * Weights significance of each part of the input data\n",
        "      * Processes sequential data (like word, an RNN) but processes entire input all at once\n",
        "      * The attention mechanism provides context, so no need to process one word at a time\n",
        "    * **BERT**, RoBERTa, T5, **GPT-2**, DistillBERT\n",
        "    * DistillBERT uses knowledge distillation to reduce model size by 40%\n",
        "  * **BERT**: Bi-directional Encoder Representations from Transformers\n",
        "  * **GPT**: Generative Pre-trained Transformers\n",
        "* **Transfer Learning**\n",
        "  * NLP models (and others) are too big and complex to build from scratch and re-train every time\n",
        "    * The latest may have hundreds of billions of parameters\n",
        "  * Model zoos such as **Hugging Face** offer pre-trained models to start from\n",
        "    * Integrated with Sagemaker via Hugging Face Deep Learning Containers\n",
        "  * You can fine-tune these models for your own use cases\n",
        "* **Transfer Learning: BERT example**\n",
        "  * Hugging Face offers a Deep Learning Container (DLC) for BERT\n",
        "  * It's a pre-trained on BookCorpus and Wikipedia\n",
        "  * You can fine-tune BERT (or DistillBERT etc) with your own additional training data through transfer learning\n",
        "    * Tokenize your own training data to be of the same format\n",
        "    * Just start training it further with your data, with a low learning rate\n",
        "* **Transfer Learning Approaches**\n",
        "  * Continue training a pre-trained model (**fine-tuning**)\n",
        "    * Use for fine-tuning a model that has way more training data than you'll ever have\n",
        "    * Use a low learning rate to ensure you are just incrementally improving the model\n",
        "  * Add new trainable layers to the top of a frozen model\n",
        "    * Learns to turn old features into predictions on new data\n",
        "    * Can do both: add new layers then fine tune as well\n",
        "  * Retrain from scratch \n",
        "    * If you have large amount of training data and it's fundamentally different from what the model was pre-trained with\n",
        "    * And you have the computing capacity for it!\n",
        "  * Use it as-is\n",
        "    * When the model's training data is what you want already\n",
        "\n",
        "<br>\n",
        "\n",
        "**DEEP LEARNING ON EC2 AND EMR**\n",
        "* EMR supports Apache MXNet and GPU instance types\n",
        "* Appropriate instance types for deep learning:\n",
        "  * P3: 8 Tesla V100 GPUs\n",
        "  * P2: 16 K80 GPUs\n",
        "  * G3: 4 M60 GPUs (all NVIDIA chips)\n",
        "* Deep Learning AMIs\n",
        "\n",
        "<br>\n",
        "\n",
        "**TUNING NEURAL NETWORKS**\n",
        "* **Learning Rate**\n",
        "  * Neural networks are trained by gradient descent (or similar means)\n",
        "  * We start at some random point and sample different solutions (weights) seeking to minimize some cost function over many *epochs*\n",
        "  * How far apart these samples are is **learning rate**\n",
        "* **Effect of Learning Rate**\n",
        "  * Too high learning rate means you might overshoot the optimal solution\n",
        "  * Too small learning rate will take too long to find the optimal solution\n",
        "  * Learning Rate is an example of a *hyperparameter*\n",
        "* **Batch Size**\n",
        "  * How many training samples are used within each batch of each epoch\n",
        "  * Somewhat counter-intuitively:\n",
        "    * Smaller batch sizes can work their way out of *local minima* more easily\n",
        "    * Batch sizes that are too large can end up getting stuck in the wrong solution\n",
        "    * Random shuffling at each epoch can make this look like very incostitent results from run to run\n",
        "* **To Recap (! important for exam !)**\n",
        "  * *Small Batch Sizes* tend to not get stuck in local minima\n",
        "  * *Large Batch Sizes* can converge on the wrong solution at random\n",
        "  * *Large Learning Rates* can overshoot the correct solution\n",
        "  * *Small Learning Rate* increase training time\n",
        "\n",
        "<br>\n",
        "\n",
        "**NEURAL NETWORKS REGULARIZATION TECHNIQUES**\n",
        "* **What is Regularization?**\n",
        "  * Preventing overfitting\n",
        "    * Models that are good at making predictions on the data they were trained on but not on new data it hasn't seen before\n",
        "    * Overfitted models have learned patterns in the training data that don't generalize to the real world\n",
        "    * Often seen as high accuracy on training data set but lower accuracy on test or evaluation data set\n",
        "      * When training and evaluating a model we use *training*, *evaluating* and *testing* data sets\n",
        "  * Regularization techniques are intended to prevent overfitting\n",
        "* **Techniques to prevent overfitting**\n",
        "  * *Complex structure*:\n",
        "    * Too many layers\n",
        "    * Too many neurons\n",
        "  * **Dropout**\n",
        "    * Just removing some neurons at random at each training step to force your model to spread its learning out a little bit better and that has a regularization effect that prevents overfitting\n",
        "  * **Early Stopping**\n",
        "    * Algorithm that detect if the validation accuracy is leveled out while the training accuracy is still increasing so we should probably stop\n",
        "\n",
        "<br>\n",
        "\n",
        "**L1 and L2 REGULARIZATION**\n",
        "* **What L1 & L2 are?**\n",
        "  * Prevent overfitting in ML in general\n",
        "  * A regularization term is added as weights are learned\n",
        "  * **L1** term is the sum of the weights (abs of the weights)\n",
        "  * **L2** term is the sum of the square of the weights\n",
        "  * Same idea can be applied to loss function\n",
        "* **What's the difference?**\n",
        "  * L1: sum of weights multiplied by λ\n",
        "    * Performs *feature selection* - entire features go to 0\n",
        "    * Computationally inefficient\n",
        "    * Sparse output\n",
        "  * L2: sum of square of weights multiplied by λ\n",
        "    * All features remain considered, just weighted\n",
        "    * Computationally efficient\n",
        "    * Dense output\n",
        "* **Why would you want L1?**\n",
        "  * Feature selection can reduce dimensionality\n",
        "    * Out of 100 features, maybe only 10 end up with non-zero coefficients\n",
        "    * The resulting sparsity can make up for its computational inefficienty\n",
        "  * But if you think all of your features are important, L2 is probably a better choice\n",
        "\n",
        "<br>\n",
        "\n",
        "**GRIEF WITH GRADIENTS**\n",
        "* **The Vanishing Gradient Descend Problem**\n",
        "  * When the slope of the learning curve approaches zero, things can get stuck\n",
        "  * We end up working with very small numbers that slow down training or even introduce numerical errors\n",
        "  * Becomes a problem with deeper networks and RNNs as these \"vanishing gradients\" propagate to deeper layers\n",
        "  * Opposite problem: **Exploding Gradients**\n",
        "* **Fixing the Vanishing Gradient Problem**\n",
        "  * Multi-level heirarchy\n",
        "    * Break up levels into their own sub-networks trained individually\n",
        "  * Long Short-Term Memory (LSTM)\n",
        "  * Residual Networks\n",
        "    * ResNet\n",
        "    * Ensemble of shorter networks\n",
        "  * Better choice of the activation function\n",
        "    * ReLU is a good choice\n",
        "* **Gradient Checking**\n",
        "  * A debugging technique\n",
        "  * Numerically check the derivatives computed during training\n",
        "  * Useful for validating code of neural network training \n",
        "    * But you're probably not going to be writing this code in the ML industry\n",
        "\n",
        "<br>\n",
        "\n",
        "**CONFUSION MATRIX**\n",
        "* **Sometimes Accuracy Doesn't Tell The Whole Story**\n",
        "  * A test for a rare disease can be 99.9% accurate by just guessing \"no\" all the time\n",
        "  * We need to understand true positives and true negatives as well as false positives and false negatives\n",
        "  * A confusion matrix show this\n",
        "  * Check multi-class matrix confusion example from the AWS docs\n",
        "\n",
        "<br>\n",
        "\n",
        "**MEASURING YOUR MODELS**\n",
        "* **Recall**\n",
        "  * Formula: TP/(TP+FN)\n",
        "  * AKA Sensitivity, True Positive Rate, Completeness\n",
        "  * % of positives rightly predicted\n",
        "  * Good choice of metric when you care a lot about false negatives\n",
        "    * e.g. fraud detection\n",
        "* **Precision**\n",
        "  * Formula: TP/(TP+FP)\n",
        "  * AKA Correct Positives\n",
        "  * % of relevant results\n",
        "  * Good choice of metric when you care a lot about false positives\n",
        "    * e.g. medical screening, drug testing\n",
        "* **Specificity**\n",
        "  * Formula: TN/(TN+FP)\n",
        "  * True negative rate\n",
        "* **F1-Score**\n",
        "  * Formula: 2TP/(2TP+FP+FN)\n",
        "  * Formula: 2((Precision*Recall)/(Precision+Recall))\n",
        "  * Harmonic mean of precision and recall\n",
        "  * When you care about precision and recall  \n",
        "* **RMSE**\n",
        "  * Root Mean Squared Error\n",
        "  * Accuracy measurement\n",
        "  * Only cares about right and wrong answers\n",
        "* **ROC Curve**\n",
        "  * Receiver Operating Characteristic Curve\n",
        "  * Plot of true positive rate (recall) vs false positive rate at various threshold settings\n",
        "  * Points above the diagonal (y=x) represent good classification (better than random)\n",
        "  * Ideal curve would just be a point in the upper-left corner\n",
        "  * The more it's bent toward the upper left the better\n",
        "* **AUC**\n",
        "  * The area under the ROC curve\n",
        "  * Area Under the Curve (AUC)\n",
        "  * Equal to probability that a classifier will rank a randomly chosen positive instance higher than a randomly chosen negative one\n",
        "  * ROC AUC of 0.5 is a useless classifier, 1.0 is perfect\n",
        "  * Commonly used metric for comparing classifiers\n",
        "\n",
        "<br>\n",
        "\n",
        "**ENSEMBLE LEARNING**\n",
        "* **Ensemble Methods**\n",
        "  * Common example: **Random Forest**\n",
        "    * Decision Trees are prone to overfitting\n",
        "    * So, make lots of decision trees and let them all vote on the result\n",
        "    * This is a random forest\n",
        "    * But how do these trees differ? Using the following concepts...\n",
        "* **Bagging**\n",
        "  * Generate N new training sets by random sampling with replacement\n",
        "  * Each resampled model can be trained in parallel\n",
        "* **Boosting**\n",
        "  * Observations are weighted\n",
        "  * Some will take part in new training sets more often\n",
        "  * Training is sequential, each classifier takes into account the previous one's success\n",
        "  * How it works: start with equal weights on each observation, at each stage we reweight the data and the model, and we run again. Iterating on that we'll get better and better results\n",
        "* **Bagging vs Boosting**\n",
        "  * **XGBoost** is the latest hotness\n",
        "  * Boosting generally yields better accuracy\n",
        "  * But bagging avoids overfitting\n",
        "  * Bagging is easier to parallelize\n",
        "  * So, depends on your goal          \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9dMvgCJOcmpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. AMAZON SAGEMAKER"
      ],
      "metadata": {
        "id": "u7JTMlc0BsmE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTRODUCING AMAZON SAGEMAKER**\n",
        "* **What is AWS Sagemaker?**\n",
        "  * **SageMaker** is built to handle the entire ML workflow\n",
        "    * Fetch, clean and prepare data\n",
        "    * Train and evaluate a model\n",
        "    * Deploy model and evaluate results in production\n",
        "  * **SageMaker** Notebooks can direct the process\n",
        "    * Notebook instances on EC2 are spun up from the console\n",
        "    * S3 data access\n",
        "    * Scikit_learn, Spark, Tensorflow\n",
        "    * Wide variety of built-in models\n",
        "    * Ability to spin up training instances\n",
        "    * Ability to deploy trained models for making predictions at scale\n",
        "    * You can use the SageMaker console instead of notebooks but here you can't write code\n",
        "* **Data Prep on SageMaker**\n",
        "  * Data usually comes from S3\n",
        "    * Ideal format varies with algorithm - often it is RecordIO/Protobuf\n",
        "  * Can also ingest from Athena, EMR, Redshift and Amazon Keyspaces DB\n",
        "  * Apache Spark integrates with Sagemaker\n",
        "  * Scikit_learn, numpy, pandas all at your disposal within a notebook\n",
        "*  **Training on SageMaker**\n",
        "  * Create a training job\n",
        "    * URL of S3 bucket with training data\n",
        "    * ML compute resources\n",
        "    * URL of S3 bucket for output\n",
        "    * ECR path to training code\n",
        "  * Training options\n",
        "    * Built-in training algorithms\n",
        "    * Spark MLLib\n",
        "    * Custom Python Tensorflow/MXNet code\n",
        "    * Your own Docker image\n",
        "    * Algorithm purchased from AWS marketplace\n",
        "* **Deploying Trained Model**\n",
        "  * Save your trained model to S3\n",
        "  * Can deploy 2 ways:\n",
        "    * Persistent endpoint for making individual predictions on demand\n",
        "    * SageMaker Batch Transform to get predictions for an entire dataset\n",
        "  * Lots of cool options\n",
        "    * Inference Pipelines for more complex processing\n",
        "    * SageMaker Neo for deploying to edge devices \n",
        "    * Elastic Inference for accelerating deep learning models\n",
        "    * Automatic scaling (increase # of endpoints as needed)\n",
        "\n",
        "<br>\n",
        "\n",
        "**--- SAGEMAKER'S BUILT-IN ALGORITHMS ---**\n",
        "\n",
        "**LINEAR LEARNER**\n",
        "* **What is it for?**\n",
        "  * Linear Regression\n",
        "    * Fit a line to your training data\n",
        "    * Predications based on that line\n",
        "  * Can handle both regression (numeric) predictions and classification predictions\n",
        "    * For classification, a linear threshold function is used\n",
        "    * Can do binary or multi-class\n",
        "* **What training input does it expect?**\n",
        "  * RecordIO-wrapped protobuf \n",
        "    * Float32 data only!\n",
        "  * CSV\n",
        "    * First column assumed to be the label\n",
        "  * File or Pipe mode both supported\n",
        "* **How is it used?**\n",
        "  * Preprocessing \n",
        "    * Training data must be *normalized* (so all features are weighted the same*)\n",
        "    * Linear Learner can do this for you automatically\n",
        "    * Input data should be *shuffled*\n",
        "  * Training\n",
        "    * Uses Stochastic Gradient Descent  \n",
        "    * Choose an optimization algorithm (Adam, AdaGrad, SGD, etc)\n",
        "    * Multiple models are optimized in parallel \n",
        "    * Tune L1, L2 regularization\n",
        "  * Validation\n",
        "    * Most optimal model is selected\n",
        "* **Important Hyperparameters**\n",
        "  * *Balance_multiclass_weights*\n",
        "    * Gives each class equal importance in loss functions\n",
        "  * *Learning_rate*, *mini_batch_size*\n",
        "  * *L1*\n",
        "    * Regularization\n",
        "  * *Wd*\n",
        "    * Weight decay (L2 regularization)\n",
        "* **Instance Types**\n",
        "  * Training\n",
        "    * Single or multi-machine CPU or GPU\n",
        "    * Multi-GPU does not help\n",
        "\n",
        "<br>\n",
        "\n",
        "**XGBOOST**\n",
        "* **What is it for?**\n",
        "  * eXtreme Gradient Boosting \n",
        "    * Boosted group of decision trees\n",
        "    * New trees made to correct the erros of previous trees\n",
        "    * Uses gradient descent to minimize loss as new trees are added\n",
        "  * It's been winning a lot of Kaggle competitions\n",
        "    * And it's fast too\n",
        "  * Can be used for classification\n",
        "  * And also for regression\n",
        "    * Using regression trees\n",
        "* **What training input does it expect?**\n",
        "  * XGBoost is weird, since it's not made for SageMaker. It's just open source XGBoost\n",
        "  * So, it takes CSV or libsvm input  \n",
        "  * AWS recently extended it to accept recordIO-protobuf and Parquet as well\n",
        "* **How is it used?**\n",
        "  * Models are serialized/deserialized with Pickle\n",
        "  * Can use as a framework within notebooks\n",
        "    * Sagemaker.xgboost\n",
        "  * Or as a built-in SageMaker algorithm\n",
        "* **Important Hyperparameters**\n",
        "  * There are a lot of them\n",
        "  * *Subsample*\n",
        "    * Prevents overfitting\n",
        "  * *Eta*\n",
        "    * Step size shrinkage, prevents overfitting\n",
        "  * *Gamma*\n",
        "    * Minimum loss reduction to create a partition, larger = more conservative\n",
        "  * *Alpha*\n",
        "    * L1 regularization term, larger = more conservative\n",
        "  * *Lambda*\n",
        "    * L2 regularization term, larger = more conservative\n",
        "  * *eval_metric*\n",
        "    * Optimize on AUC, error, RMSE\n",
        "    * For example, if you care about false positives more than accuracy, you might use AUC here\n",
        "  * *scale_pos_weight*\n",
        "    * Adjusts balance of positive and negative weights\n",
        "    * Helpful for unbalanced classes\n",
        "    * Might set to sum(negative cases) / sum(positive cases)\n",
        "  * *max_depth*\n",
        "    * Max depth of the tree\n",
        "    * Too high and you may overfit     \n",
        "* **Instance Types**\n",
        "  * Uses CPUs only for multiple instance training\n",
        "  * Is memory-bound, not compute-bound\n",
        "  * So, **M5** is a good choice\n",
        "  * As of XGBoost 1.2, single instance GPU training is available\n",
        "    * For example **P3**\n",
        "    * Must set *tree_method* hyperparameter to *gpu_hist*\n",
        "    * Trains more quickly and can be more cost effective\n",
        "\n",
        "<br>\n",
        "\n",
        "**SEQ2SEQ**\n",
        "* **What is it for?**\n",
        "  * Sequence to Sequence\n",
        "  * Input is a sequence of tokens, output is a sequence of tokens\n",
        "  * Machine Translation\n",
        "  * Text Summarization\n",
        "  * Speech to Text\n",
        "  * Implemented with RNNs and CNNs with attention\n",
        "* **What training input does it expect?**\n",
        "  * RecordIO-Protobuf\n",
        "    * Tokens must be integers (this is unusual, since most algorithms want floating point data)\n",
        "  * Start with tokenized text files\n",
        "  * Convert to protobuf using sample code\n",
        "    * Packs into integer tensors with vocabulary files\n",
        "    * A lot like the TF/IDF lab we did earlier\n",
        "  * Must provide training data, validation data and vocabulary files\n",
        "* **How is it used?**\n",
        "  * Training for machine translation can take days even on SageMaker\n",
        "  * Pre-trained models are available\n",
        "    * See the example notebook\n",
        "  * Public training datasets are available for specific translation tasks\n",
        "* **Important Hyperparameters**\n",
        "  * *Batch_size*\n",
        "  * *Optimizer_type* (adam, sgd, rmsprop)\n",
        "  * *Learning_rate*\n",
        "  * *Num_layers_encoder*\n",
        "  * *Num_layers_decoder*\n",
        "  * Can optimize on:\n",
        "    * Accuracy\n",
        "      * vs provided validation dataset\n",
        "    * BLEU score\n",
        "      * Compares against multiple reference translations\n",
        "    * Perplexity\n",
        "      * Cross-entropy\n",
        "* **Instance Types**\n",
        "  * Can only use GPU instance types (**P3** for example)\n",
        "  * Can only use a single machine for training \n",
        "    * But can use multi-GPUs on one machine\n",
        "\n",
        "<br>\n",
        "\n",
        "**DEEPAR**\n",
        "* **What is it for?**\n",
        "  * **Forecasting** one-dimensional time series data\n",
        "  * Uses RNNs\n",
        "  * Allows you to train the same model over several related time series\n",
        "  * Finds frequencies and seasonality\n",
        "* **What training input does it expect?**\n",
        "  * JSON lines format\n",
        "    * Gzip or Parquet\n",
        "  * Each record must contain:\n",
        "    * Start: the starting time stamp\n",
        "    * Target: the time series values\n",
        "  * Each record can contain:\n",
        "    * *Dynamic_feat*: dynamic features (such as, was a promotion applied to a product in a time series or product purchases)\n",
        "    * *Cat*: categorical features   \n",
        "* **How is it used?**\n",
        "  * Always include entire time series for training, testing and inference\n",
        "  * Use entire dataset as a test set, remove last time points fro training. Evaluate on withheld values\n",
        "  * Don't use very large values for prediction length (> 400)\n",
        "  * Train on many time series and not just one when possible\n",
        "* **Important Hyperparameters**\n",
        "  * *Context_length*\n",
        "    * Number of time points the model sees before making a prediction\n",
        "    * Can be smaller than a seasonalities, the model will lag one year anyhow\n",
        "  * *Epochs*\n",
        "  * *mini_batch_size*\n",
        "  * *Learning_rate*\n",
        "  * *Num_cells*\n",
        "* **Instance Types**\n",
        "  * Can use CPU or GPU\n",
        "  * Single or multi machine\n",
        "  * Start with CPU (C4.2xlarge, C4.4xlarge)\n",
        "  * Move up to GPU if necessary\n",
        "    * Only helps with larger models\n",
        "  * CPU only for inference\n",
        "  * May need larger instances for tuning\n",
        "\n",
        "<br>\n",
        "\n",
        "**BLAZINGTEXT**\n",
        "* **What is it for?**\n",
        "  * Text classification\n",
        "    * Predict labels for a sentence\n",
        "    * Useful in web searches, information retrieval\n",
        "    * Supervised\n",
        "  * Word2vec\n",
        "    * Word embedding layer\n",
        "    * Creates a vector representation of words\n",
        "    * Semantically similar words are represented by vectors close to each other\n",
        "    * This is called a *word embedding*\n",
        "    * It's useful for NLP but is not an NLP algorithm in itself\n",
        "      * Used in machine translation, sentiment analysis\n",
        "    * Remember it only works on individual words not sentences or document    \n",
        "* **What training input does it expect?**\n",
        "  * For supervised mode (text classification):\n",
        "    * One sentence per line\n",
        "    * First \"word\" in the sentence is the string \\__label__ followed by the label\n",
        "    * Also, \"augmented manifest text format\"\n",
        "    * Word2vec just wants a text file with one training sentence per line\n",
        "* **How is it used?**\n",
        "  * Word2vec has multiple modes\n",
        "    * Cbow (Con tinuous Bag of Words)\n",
        "    * Skip-gram\n",
        "    * Batch skip-gram\n",
        "      * Distributed computation over many CPU nodes \n",
        "* **Important Hyperparameters**\n",
        "  * Word2vec:\n",
        "    * *Mode (batch_skipgram, skipgram, cbow)*\n",
        "    * *Learning_rate*\n",
        "    * *Window_size*\n",
        "    * *Vector_dim*\n",
        "    * *Negative_samples*\n",
        "  * Text Classification\n",
        "    * *Epochs*\n",
        "    * *Learning_rate*\n",
        "    * *Word_ngrams*\n",
        "    * *Vector_dim*  \n",
        "* **Instance Types**\n",
        "  * For cbow and skipgram, recommend a single *ml.p3.2xlarge*\n",
        "    * Any single CPU or single GPU instance will work\n",
        "  * For *batch_skipgram* can use a single or multiple CPU instances\n",
        "  * For text classification, *C5* recommended if less than 2GB of data. For larger data sets use a single GPU instance (*ml.p2.xlarge or ml.p3.2xlarge*) \n",
        "\n",
        "<br>\n",
        "\n",
        "**OBJECT2VEC**\n",
        "* **What is it for?**\n",
        "  * Remember word2vec from BlazingText? It's like that but arbitrary objects\n",
        "  * It creates low-dimensional dense embeddings of high-dimensional objects\n",
        "  * It's basically word2vec generalized to handle things other than words\n",
        "  * Compute nearest neighbors of objects\n",
        "  * Visualize clusters\n",
        "  * Genre prediction\n",
        "  * Recommendations (similar items or users)\n",
        "* **What training input does it expect?**\n",
        "  * Data must be tokenized inot integers\n",
        "  * Training data consists of pairs of tokens and/or sequences of tokens\n",
        "    * Sentence - sentence\n",
        "    * Labels - sequence (genre to description?)\n",
        "    * Customer - customer\n",
        "    * Product - product\n",
        "    * User - item\n",
        "* **How is it used?**\n",
        "  * Process data into JSON Lines and shuffle it\n",
        "  * Train with two input channels, two encoders and a comparator\n",
        "  * Encoder choices:\n",
        "    * Average-pooled embeddings\n",
        "    * CNNs\n",
        "    * Bidirectional LSTM\n",
        "  * Comparator is followed by a feed-forward neural network  \n",
        "* **Important Hyperparameters**\n",
        "  * The usual deep learning ones\n",
        "    * *Dropout*, *early_stopping*, *epochs*, *learning_rate*, *batch_size*, *layers*, *activation function*, *optimizer*, *weight decay*\n",
        "  * Enc1_network, enc2_network\n",
        "    * Choose hcnn, bilstm, pooled_embedding  \n",
        "* **Instance Types**\n",
        "  * Can only train on a single machine (CPU or GPU, multi-GPU OK)\n",
        "    * ml.m5.2xlarge\n",
        "    * ml.p2.xlarge\n",
        "    * If needed go up to ml.m5.4xlarge or ml.m5.12xlarge\n",
        "  * Inference: use ml.p2.2xlarge\n",
        "    * Use INFERENCE_PREFERRED_MODE environment variable to optimize for encoder embeddings rather than classification or regression\n",
        "\n",
        "<br>\n",
        "\n",
        "**OBJECT DETECTION**\n",
        "* **What is it for?**\n",
        "  * Identify all objects in an image with bounding boxes\n",
        "  * Detects and classifies objects with a single deep neural network\n",
        "  * Classes are accompanied by confidence scores\n",
        "  * Can train from scratch or use pre-trained models based on ImageNet\n",
        "* **What training input does it expect?**\n",
        "  * RecordIO or image format (jpg or png)\n",
        "  * With image format, supply a JSON file for annotation data for each image\n",
        "* **How is it used?**\n",
        "  * Takes an image as input, outputs all instances of objects in the image with categories and confidence scores\n",
        "  * Uses a CNN with the Single Shot multibox Detector (SSD) algorithm\n",
        "    * The base CNN can be VGG-16 or ResNet-50\n",
        "  * Transfer Learning mode / incremental training\n",
        "    * Use a pre-trained model for the base network weights, instead of random initial weights\n",
        "  * Use flips, rescale and jitter internally to avoid overfitting    \n",
        "* **Important Hyperparameters**\n",
        "  * *Mini_batch_size*\n",
        "  * *Learning_rate*\n",
        "  * *Optimizer*\n",
        "    * *sgd*, *adam*, *rmsprop*, *adadelta*\n",
        "* **Instance Types**\n",
        "  * Use GPU instances for training (multi GPU and multi-machine OK)\n",
        "    * ml.p2.xlarge, ml.p2.8xlarge, ml.p2.16xlarge, ml.p3.2xlarge, ml.p3.8clarge, ml.p3.16xlarge\n",
        "  * Use CPU or CPU for inference\n",
        "    * C5, M5, P2, P3 all OK\n",
        "\n",
        "<br>\n",
        "\n",
        "**IMAGE CLASSIFICATION**\n",
        "* **What is it for?**\n",
        "  * Assign one or more labels to an image\n",
        "  * Doesn't tell you where objects are, just what objects are in the image\n",
        "* **What training input does it expect?**\n",
        "  * Apache MXNet RecordIO\n",
        "    * Not Protobuf\n",
        "    * This is for interoperability with other deep learning frameworks\n",
        "  * Or raw jpg or png images\n",
        "  * Image format requires .lst files to associate image index, class label and path to the image\n",
        "  * Augmented manifest image format enables Pipe mode  \n",
        "* **How is it used?**\n",
        "  * ResNet CNN under the hood\n",
        "  * Full training mode\n",
        "    * Network initialized with random weights\n",
        "  * Transfer learning mode\n",
        "    * Initialized with pre-trained weights\n",
        "    * The top fully-connected layer is initialized with random weights\n",
        "    * Network is fine-tuned with new training data\n",
        "  * Default image size is 3-channel 224x224 (ImageNet's dataset)    \n",
        "* **Important Hyperparameters**\n",
        "  * The usual suspects for deep learning\n",
        "    * *Batch size*, *learning rate*, *optimizer*\n",
        "  * Optimizer-specific parameters\n",
        "    * Weight decay, beta 1, beta 2, eps, gamma  \n",
        "* **Instance Types**\n",
        "  * GPU instances for training (P2, P3)\n",
        "  * Multi-GPU and multi-machine is OK\n",
        "  * CPU or GPU for inference (C4, P2, P3)\n",
        "\n",
        "<br>\n",
        "\n",
        "**SEMANTIC SEGMENTATION**\n",
        "* **What is it for?**\n",
        "  * Pixel-level object classification\n",
        "  * Different from image classification - that assigns labels to whole images\n",
        "  * Different from object detection - that assigns labels to bounding boxes \n",
        "  * Useful for self-driving vehicles, medical imaging diagnostic, robot sensing\n",
        "  * Produces a *segmentation mask* \n",
        "* **What training input does it expect?**\n",
        "  * JPG images and PNG annotations\n",
        "  * For both training and validation\n",
        "  * Label maps to describe annotations\n",
        "  * Augmented manifest image format supported for Pipe mode\n",
        "  * JPG images accepted for inference\n",
        "* **How is it used?**\n",
        "  * Built on MXNet Gluon and Gluon CV\n",
        "  * Choice of 3 algorithms:\n",
        "    * Fully-Convolutional Network (FCN)\n",
        "    * Pyramid Scene Parsing (PSP)\n",
        "    * DeepLabV3\n",
        "  * Choice of backbones:\n",
        "    * ResNet50\n",
        "    * ResNet101\n",
        "    * Both trained on ImageNet\n",
        "  * Incremental training or training from scratch, supported too    \n",
        "* **Important Hyperparameters**\n",
        "  * *Epochs*, *learing_rate*, *batch_size*, *optimizer*\n",
        "  * Algorithm\n",
        "  * Backbone  \n",
        "* **Instance Types**\n",
        "  * Only GPU supported for training (P2 or P3) on a single machine only\n",
        "    * Specifically ml.p2.xlarge, ml.p2.8xlarge, ml.p2.16xlarge, ml.p3.2xlarge, ml.p3.8xlarge, ml.p3.16xlarge \n",
        "  * Inference on CPU (C5 or M5) or GPU (P2 or P3)\n",
        "\n",
        "<br>\n",
        "\n",
        "**RANDOM CUT FOREST**\n",
        "* **What is it for?**\n",
        "  * Anomaly Detection\n",
        "  * Unsupervised\n",
        "  * Detect unexpected spikes in time series data\n",
        "  * Breaks in periodicity\n",
        "  * Unclassifiable data points\n",
        "  * Assigns an anomaly score to each data point\n",
        "  * Based on an algorithm developed by Amazon that they seem to be very proud of!\n",
        "* **What training input does it expect?**\n",
        "  * RecordIO-protobuf or CSV\n",
        "  * Can use File or Pipe mode on either\n",
        "  * Optional test channel for computing accuracy, precision, recall and F1 on labeled data (anomaly or not)\n",
        "* **How is it used?**\n",
        "  * Creates a forest of trees where each tree is a partition of the training data; looks at expected change in complexity of the tree as a result of adding a point into it\n",
        "  * Data is sampled randomly\n",
        "  * Then trained\n",
        "  * RCF shows up in Kinesis Analytics as well; it can work on streaming data too\n",
        "* **Important Hyperparameters**\n",
        "  * *Num_trees*\n",
        "    * Increasing reduces noise\n",
        "  * *Num_samples_per_tree*\n",
        "    * Should be chosen such that 1/*num_samples_per_tree* approximates the ratio of anomalous to normal data\n",
        "* **Instance Types**\n",
        "  * Does not take advantage of GPUs\n",
        "  * Use M4, C4 or C5 for training\n",
        "  * ml.c5.xl for inference\n",
        "\n",
        "<br>\n",
        "\n",
        "**NEURAL TOPIC MODEL**\n",
        "* **What is it for?**\n",
        "  * Organize document into topics\n",
        "  * Classify or summarize documents based on topics\n",
        "  * It's not just TF/IDF\n",
        "    * \"bike\", \"car\", \"train\", \"mileage\" and \"speed\" might classify a document as \"transportation\" for example (although it wouldn't know to call it that)\n",
        "  * Unsupervised\n",
        "    * Algorithm is \"Neural Variational Inference\"  \n",
        "* **What training input does it expect?**\n",
        "  * Four data channels:\n",
        "    * \"train\" is required\n",
        "    * \"validation\", \"test\" and \"auxiliary\" optional\n",
        "  * recordIO-protobuf or CSV\n",
        "  * Words must be tokenized into integers\n",
        "    * Every document must contain a count for every word in the vocabulary in CSV\n",
        "    * The \"auxiliary\" channel is for the vocabulary\n",
        "  * File or Pipe mode (Pipe always faster)    \n",
        "* **How is it used?**\n",
        "  * You define how many topics you want\n",
        "  * These topics are a latent representation based on top ranking words\n",
        "  * One of two topic modeling algorithms in SageMaker - you can try them both!\n",
        "* **Important Hyperparameters**\n",
        "  * Lowering *mini_batch* and *learning_rate* can reduce validation loss\n",
        "    * At expense of training time\n",
        "  * Num_topics  \n",
        "* **Instance Types**\n",
        "  * GPU or CPU\n",
        "    * GPU recommended for training\n",
        "    * CPU OK for inference\n",
        "    * CPU is cheaper\n",
        "\n",
        "<br>\n",
        "\n",
        "**LATENT DIRICHLET ALLOCATION (LDA)**\n",
        "* **What is it for?**\n",
        "  * Another topic modeling algorithm\n",
        "    * Not Deep Learning\n",
        "  * Unsupervised\n",
        "    * The topics themselves are unlabeled; they are just groupings of documents with a shared subset of words\n",
        "  * Can be used for things other than words\n",
        "    * Cluster customers based on purchased\n",
        "    * Harmonic analysis in music    \n",
        "* **What training input does it expect?**\n",
        "  * Train channel, optional test channel\n",
        "  * recordIO-protobuf of CSV\n",
        "  * Each document has counts for every word in vocabulary (in CSV format)\n",
        "  * Pipe mode only supported with recordIO\n",
        "* **How is it used?**\n",
        "  * Unsupervised; generates however many topics you specify\n",
        "  * Optional test channel can be used for scoring results\n",
        "    * Per-word log likelihood\n",
        "  * Functionally similar to NTM but CPU-based\n",
        "    * Therefore maybe cheaper / more efficient  \n",
        "* **Important Hyperparameters**\n",
        "  * *Num_topics*\n",
        "  * *Alpha0*\n",
        "    * Initial guess for concentration parameter\n",
        "    * Smaller values generate sparse topic mixtures\n",
        "    * Larger values (> 1.0) produce uniform mixture\n",
        "* **Instance Types**\n",
        "  * Single-instance CPU training\n",
        "\n",
        "<br>\n",
        "\n",
        "**K-NEAREST-NEIGHBORS (KNN)**\n",
        "* **What is it for?**\n",
        "  * Simple classification or regression algorithm\n",
        "  * Classification\n",
        "    * Find the K closest points to a sample point and return the most frequent label\n",
        "  * Regression\n",
        "    * Find the K closest points to a sample point and return the average value   \n",
        "* **What training input does it expect?**\n",
        "  * Train channel contains your data\n",
        "  * Test channel emits accuracy or MSE\n",
        "  * recordIO-protobuf or CSV training\n",
        "    * First column is label\n",
        "  * File or Pipe mode on either  \n",
        "* **How is it used?**\n",
        "  * Data is first sampled\n",
        "  * SageMaker includes a dimensionality reduction stage\n",
        "    * Avoid sparse data (\"curse of dimensionality\")\n",
        "    * At cost of noise/accuracy\n",
        "    * \"sign\" of \"fjlt\" methods\n",
        "  * Build an index for looking up neighbors\n",
        "  * Serialize the model\n",
        "  * Query the model for a given K   \n",
        "* **Important Hyperparameters**\n",
        "  * *K*\n",
        "  * *Sample_size*\n",
        "* **Instance Types**\n",
        "  * Training on CPU or GPU\n",
        "    * ml.m5.2xlarge \n",
        "    * ml.p2.xlarge\n",
        "  * Inference\n",
        "    * CPU for lower latency\n",
        "    * GPU for higher throughput on large batches\n",
        "\n",
        "<br>\n",
        "\n",
        "**K-MEANS CLUSTERING**\n",
        "* **What is it for?**\n",
        "  * Unsupervised clustering \n",
        "  * Divide data into K groups, where members of a group are similar as possible to each other\n",
        "    * You define what \"similar\" means\n",
        "    * Measured by Euclidean distance\n",
        "  * Web-scale K-Means clustering  \n",
        "* **What training input does it expect?**\n",
        "  * Train channel, optional test\n",
        "    * Train ShardedByS3Key, Test FullyReplicated\n",
        "  * recordIO-protobuf or CSV\n",
        "  * File or Pipe on either  \n",
        "* **How is it used?**\n",
        "  * Every observation mapped to n-dimensional space (n = number of features)\n",
        "  * Works to optimize the center of K clusters\n",
        "    * \"extra cluster centers\" may be specified to improve accuracy (which end up getting reduced to k)\n",
        "    * K = k * x\n",
        "  * Algorithm:\n",
        "    * Determine initial cluster centers\n",
        "      * Random or K-Means++ approach\n",
        "      * K-Means tries to make initial clusters far apart\n",
        "    * Iterate over training data and calculate cluster centers\n",
        "    * Reduce clusters from K to k\n",
        "      * Using Lloyd's method with K-Means++    \n",
        "* **Important Hyperparameters**\n",
        "  * K\n",
        "    * Choosing K is tricky\n",
        "    * Plot within-cluster sum of squares as function of K\n",
        "    * Use \"Elbow-Method\"\n",
        "    * Basically optimize for tightness of clusters\n",
        "  * *Mini_batch_size*\n",
        "  * *Extra_center_factor*\n",
        "  * *Init_method*   \n",
        "* **Instance Types**\n",
        "  * CPU or GPU, but CPU recommended \n",
        "    * Only one GPU per instance used on GPU\n",
        "    * So use p*.xlarge if you're going to use GPU\n",
        "\n",
        "<br>\n",
        "\n",
        "**PRINCIPAL COMPONENT ANALYSIS**\n",
        "* **What is it for?**\n",
        "  * Dimensionality reduction\n",
        "    * Project higher-dimensional data (lots of features) into lower-dimensional (like a 2D plot) while minimizing loss of information\n",
        "    * The reduced dimensions are called componenets\n",
        "      * First component has the largest possible variability\n",
        "      * Second component has the next largest variability etc\n",
        "  * Unsupervised    \n",
        "* **What training input does it expect**\n",
        "  * recordIO-protobuf or CSV\n",
        "  * File or Pipe on either\n",
        "* **How is it used?**\n",
        "  * Covariance matrix is created, then singular value decomposition (SVD)\n",
        "  * Two modes:\n",
        "    * *Regular*: for sparse data and moderate number of observations and features\n",
        "    * *Randomized*: for large number of observations and features and it uses approximation algorithm\n",
        "* **Important Hyperparameters**\n",
        "  * *Algorithm_mode*\n",
        "  * *Subtract_mean*\n",
        "    * Unbias data\n",
        "* **Instance Types**\n",
        "  * GPU or CPU\n",
        "    * It depends \"on the specific of the input data\"\n",
        "\n",
        "<br>\n",
        "\n",
        "**FACTORIZATION MACHINES**\n",
        "* **What is it for?**\n",
        "  * Dealing with sparse data\n",
        "    * Click prediction\n",
        "    * Item recommendations\n",
        "    * Since an individual user doesn't interact with most pages/products the data is sparse\n",
        "  * Supervised\n",
        "    * Classification or regression\n",
        "  * Limited to pair-wise interactions\n",
        "    * User -> item for example    \n",
        "* **What training input does it expect**\n",
        "  * recordIO-protobuf with Float32\n",
        "    * Sparse data means CSV isn't practical because you just end up with a huge list of commas because the vast majority of the items are not gonna have any data associated with them\n",
        "* **How is it used?**\n",
        "  * Finds factors we can use to predict a classification (click or not? Purchase or not?) or value (predicted rating?) given a matrix representing some pair of things (users & items?)\n",
        "  * Usually used in the context of recommender systems\n",
        "* **Important Hyperparameters**\n",
        "  * Initialization methods for bias, factors and linear terms\n",
        "    * Uniform, normal or constant\n",
        "    * Can tune properties of each method\n",
        "* **Instance Types**\n",
        "  * CPU or GPU \n",
        "    * CPU recommended\n",
        "    * GPU only works with dense data\n",
        "\n",
        "<br>\n",
        "\n",
        "**IP INSIGHTS**\n",
        "* **What is it for?**\n",
        "  * Unsupervised learning of IP address usage patterns\n",
        "  * Identifies suspicious behaviour from IP addresses\n",
        "    * Identify logins from anomalous IPs\n",
        "    * Identify accounts creating resources from anomalous IPs\n",
        "* **What training input does it expect?**\n",
        "  * User names, account IDs can be fed in directly, no need to pre-process\n",
        "  * Training channel, optional validation (computes AUC score)\n",
        "  * CSV only \n",
        "    * Entity, IP\n",
        "* **How is it used?**\n",
        "  * Uses a neural network to learn latent vector representations of entities and IP addresses\n",
        "  * Entities are hashed and embedded\n",
        "    * Need sufficiently large hash size\n",
        "  * Automatically generates negative samples during training by randomly pairing entities and IPs  \n",
        "* **Important Hyperparameters**\n",
        "  * *Num_entity_vectors*\n",
        "    * Hash size\n",
        "    * Set to twice the number of unique entity identifiers\n",
        "  * *Vector_dim*\n",
        "    * Size of embedding vectors\n",
        "    * Scales model size\n",
        "    * Too large results in overfitting\n",
        "  * Epochs, learning rate, batch size, etc  \n",
        "* **Instance Types**\n",
        "  * CPU or GPU\n",
        "    * GPU recommended\n",
        "    * ml.p3.2xlarge or higher\n",
        "    * Can use multiple GPUs\n",
        "    * Size of CPU instance depends on *vector_dim* and *num_entity_vectors*\n",
        "\n",
        "<br>\n",
        "\n",
        "**REINFORCEMENT LEARNING**\n",
        "* **What is RL?**\n",
        "  * You have some sort of agent that \"explores\" some space\n",
        "  * As it goes, it learns the value of different state changes in different conditions\n",
        "  * Those values inform subsequent behaviour of the agent\n",
        "  * Examples: Pac-Man, Cat & Mouse game (game AI)\n",
        "    * Supply chain management\n",
        "    * HVAC systems\n",
        "    * Industrial robotics\n",
        "    * Dialog systems\n",
        "    * Autonomous vehicles\n",
        "  * Yields fast on-line performance once the space has been explored\n",
        "* **Q-Learning**\n",
        "  * A specific implementation of RL\n",
        "  * You have:\n",
        "    * A set of environmental states *s*\n",
        "    * A set of possible actions in those state *a*\n",
        "    * A value of each state/action *Q*\n",
        "  * Start off with Q values of 0\n",
        "  * Explore the space\n",
        "  * As bad things happen after a given state/action, reduce its *Q*\n",
        "  * As rewards happen after a given state/action, increase its *Q*\n",
        "* **The Exploration Problem**\n",
        "  * How do we efficiently explore all of the possible states?\n",
        "    * Simple approach: always choose the action for a given state with the highest *Q*. If there's a tie, choose at random\n",
        "      * But that's really inefficient and you might miss a lot of paths that way\n",
        "    * Better way: introduce an epsilon term\n",
        "      * If a random number is less than epsilon, don't follow the highest *Q* but choose at random\n",
        "      * That way exploration never totally stops\n",
        "      * Choosing epsilon can be tricky\n",
        "* **Fancy Words**\n",
        "  * Markov Decision Process\n",
        "    * From Wikipedia: **Markov Decision Processes (MDPs)** provide a mathematical framework for modeling decision making in situations where outcome are partly random and partly under the control of a decision maker\n",
        "    * Sound familiar? MDPs are just a way to describe what we just did using mathematical notation\n",
        "    * States are still described as *s* and *s'*\n",
        "    * State transition functions are described as *Pa*(*s*,*s'*)\n",
        "    * Our *Q* values are described as a reward function *Ra*(*s*,*s'*)\n",
        "  * Even fancier words! An MDP is a *discrete time stochastic control process*\n",
        "* **Recap**\n",
        "  * You can make an intelligent Pac-Man in a few steps:\n",
        "    * Have it semi-randomly explore different choices of movement (actions) given different conditions (states)\n",
        "    * Keep track of the reward or penalty associated with each choice for a given state/action (*Q*)\n",
        "    * Use those stored *Q* values to inform its future choices\n",
        "  * Pretty simple concept. But hey, now you can say you understand RL, Q-Learning, Markov Decision Processes and Dymanic Programming!\n",
        "* **RL in SageMaker**\n",
        "  * Uses a DL framework with Tensorflow and MXNet\n",
        "  * Supports Intel Coach and Ray Rllib toolkits\n",
        "  * Custom, open-source or commercial environments supported\n",
        "    * MATLAB, Simulink\n",
        "    * EnergyPlus, RoboSchool, PyBullet\n",
        "    * Amazon Sumerian, AWS RoboMaker\n",
        "* **Distributed Training with SageMaker RL**\n",
        "  * Can distribute training and/or environment rollout\n",
        "  * Multi-core and multi-instance\n",
        "* **RL Key Terms**\n",
        "  * *Environment*\n",
        "    * The layout of the board/maze/etc\n",
        "  * *State*\n",
        "    * Where the player/pieces are\n",
        "  * *Action*\n",
        "    * Move in a given direction, etc\n",
        "  * *Reward*\n",
        "    * Value associated with the action from that state\n",
        "  * *Observation*\n",
        "    * e.g. surrounding in a maze, state of a chess board\n",
        "* **Hyperparameter Tuning**\n",
        "  * Parameters of your choosing may be abstracted\n",
        "  * Hyperparameter tuning in SageMaker can then optimize them\n",
        "* **Instance Types**\n",
        "  * No specific guidance given in developer guide\n",
        "  * But, it's deep learning - so GPUs are helpful\n",
        "  * And we know it supports multiple instances and cores\n",
        "\n",
        "<br>\n",
        "\n",
        "**AUTOMATIC MODEL TUNING**\n",
        "* **HyperParameter Tuning**\n",
        "  * How do you know the best values of learning rate, batch size, depth, etc?\n",
        "  * Often you have to experiment\n",
        "  * Problem blows up quickly when you have many different hyperparameters; need to try every combination of every possible value somehow, train a model and evaluate it every time\n",
        "* **Automatic Model Tuning**\n",
        "  * Define the hyperparameters you care about and the ranges you want to try, and the metrics you are optimizing for\n",
        "  * SageMaker spins up a \"HyperParameter Tuning Job\" that trains as many combinations as you'll allow\n",
        "    * Training instances are spun up as needed, potentially a lot of them \n",
        "    * The set of hyperparameters producing the best results can then be deployed as a model\n",
        "    * **It learn as it goes**, so it doens't have to try every possible combination\n",
        "* **Best Practices**\n",
        "  * Don't optimize too many hyperparameters at once\n",
        "  * Limit your ranges to as small a range as possible\n",
        "  * Use logarithmic scales when appropriate\n",
        "  * Don't run too many training jobs concurrently\n",
        "    * This limits  how well the process can learn as it goes\n",
        "  * Make sure training jobs running on multiple instances report the correct objective metric in the end\n",
        "\n",
        "<br>\n",
        "\n",
        "**APACHE SPARK**\n",
        "* **Integrating SageMaker and Spark**\n",
        "  * Pre-process data as normal with Spark\n",
        "    * Generate DataFrames\n",
        "  * Use sagemaker-spark library\n",
        "  * SageMakerEstimator \n",
        "    * KMeans, PCA, XGBoost\n",
        "  * SageMakerModel\n",
        "* **The Way It Works**\n",
        "  * Connect notebook to a remote EMR cluster running Spark (or use Zeppelin)\n",
        "  * Training dataframe should have:\n",
        "    * A features column that is vector of Doubles\n",
        "    * An optional labels column of Doubles\n",
        "  * Call fit on your SageMakerEstimator to get a SageMakerModel\n",
        "  * Call transform on the SageMakerModel to make inferences\n",
        "  * Works with Spark Pipelines as well\n",
        "* **Why Bother?**\n",
        "  * Allows you to combine pre-processing big data in Spark with training and inference in SageMaker\n",
        "\n",
        "<br>\n",
        "\n",
        "**NEW SAGEMAKER FEATURES**\n",
        "* **SageMaker Studio**\n",
        "  * Visual IDE for ML\n",
        "  * Integrates many of the features we're about to cover\n",
        "* **SageMaker Notebooks**\n",
        "  * Create and share Jupyter Notebooks with SageMaker Studio\n",
        "  * Switch between hardware configurations (no infrastructure to manage)\n",
        "* **SageMaker Experiments**\n",
        "  * Organize, capture, compare and search your ML jobs\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER DEBUGGER**\n",
        "* **What is?**\n",
        "  * Saves internal model state at periodical intervals\n",
        "    * Gradients/tensors over time as a model is trained\n",
        "    * Define rules for detecting unwanted conditions while training \n",
        "    * A debug job is run for each rule you configure\n",
        "    * Logs & fires a CloudWatch event when the rule is hit\n",
        "  * SageMaker Studio Debugger dashboards\n",
        "  * Auto-generated training reports\n",
        "  * Built-in rules:\n",
        "    * Monitor system bottlenecks\n",
        "    * Profile model framework operations\n",
        "    * Debug model parameters\n",
        "  * Supported Frameworks & Algorithms:\n",
        "    * Tensorflow\n",
        "    * PyTorch\n",
        "    * MXNet\n",
        "    * XGBoost\n",
        "    * SageMaker generic estimator (for use with custom training containers)\n",
        "  * Debugger APIs available in GitHub\n",
        "    * Construct hooks & rules for CreateTrainingJob and DescribeTrainingJob APIs\n",
        "    * SMdebug client library lets you register hooks for accessing training data\n",
        "* **Newer SageMaker Debugger Features**\n",
        "  * SageMaker Debugger Insights Dashboards\n",
        "  * Debugger ProfilerRule\n",
        "    * ProfilerReport\n",
        "    * Hardware system metrics (CPUBottleneck, GPUMemoryIncrease, etc)\n",
        "    * Framework Metrics (MaxInitializationTime, OverallFrameworkMetrics, StepOutlier)\n",
        "  * Built-in actions to receive notifications or stop training\n",
        "    * StopTraining(), Email() or SMS()\n",
        "    * In response to Debugger Rules\n",
        "    * Sends notifications vis SNS\n",
        "  * Profiling system resource usage and training\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER AUTOPILOT/AUTOML**\n",
        "* **SageMaker Autopilot**\n",
        "  * Automates:\n",
        "    * Algorithm selection\n",
        "    * Data preprocessing\n",
        "    * Model tuning\n",
        "    * All infrastructure\n",
        "  * It does all the trial & error for you\n",
        "  * More broadly this is called AutoML\n",
        "  * Can add in human guidance\n",
        "  * With or without code in SageMaker Studio or AWS SDKs\n",
        "  * Problem Types:\n",
        "    * Binary calssification\n",
        "    * Multiclass classification\n",
        "    * Regression\n",
        "  * Algorithm Types:\n",
        "    * Linear Learner\n",
        "    * XGBoost\n",
        "    * Deep Learning (MLPs)\n",
        "  * Data must be tabular CSV    \n",
        "* **SageMaker Autopilot Workflow**\n",
        "  * Load data from S3 for training\n",
        "  * Select your target column for prediction\n",
        "  * Automatic model creation\n",
        "  * Model notebook is available for visibility & control\n",
        "  * Model leaderboard\n",
        "    * Ranked list of recommended models\n",
        "    * You can pick one\n",
        "  * Deploy & monitor the model, refine via notebook if needed\n",
        "* **Autopilot Explainability**\n",
        "  * Integrates with SageMaker Clarify\n",
        "  * Transparency on how models arrive at predictions\n",
        "  * Feature attribution\n",
        "    * Uses SHAP Baselines/Shapley Values\n",
        "    * Research from cooperative game theory\n",
        "    * Assigns each feature an importance value for a given prediction\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER MODEL MONITOR**\n",
        "* **What is?**\n",
        "  * Get alerts on quality deviations on your deployed models (via CloudWatch)\n",
        "  * Visualize data drift\n",
        "    * Example: loan model starts giving people more credit due to drifting or missing input features\n",
        "    * Detect anomalies & outliers\n",
        "    * Detect new features\n",
        "    * No code needed\n",
        "  * Data is stored in S3 and secured\n",
        "  * Monitoring jobs are scheduled via a Monitoring Schedule\n",
        "  * Metrics are emitted to CloudWatch\n",
        "    * CloudWatch notifications can be used to trigger alarms\n",
        "    * You'd then take corrective action (retrain the model, audit the data)\n",
        "  * Integrates with Tensorboard, QuickSight and Tableau\n",
        "    * Or just visualize within SageMaker Studio\n",
        "  * Monitoring Types:\n",
        "    * Drift in data quality\n",
        "      * Relative to a baseline you create\n",
        "      * \"Quality\" is just statistical properties of the features\n",
        "    * Drift in model quality (accuracy, etc)\n",
        "      * Works the same way with a model quality baseline\n",
        "      * Can integrate with Ground Truth labels\n",
        "    * Bias drift\n",
        "    * Feature attribution drift\n",
        "      * Based on Normalized Discounted Cumulative Gain (NDCG) score\n",
        "      * This compares feature ranking of training vs live data    \n",
        "* **SageMaker Model Monitor + Clarify**\n",
        "  * Integrates with SageMaker Clarify\n",
        "    * SageMaker Clarify detects potential bias\n",
        "    * e.g. imbalances across different groups/ages/income brackets\n",
        "    * With ModelMonitor you can monitor for bias and be alerted to new potential bias via CloudWatch\n",
        "    * SageMaker Clarify also helps explain model behaviour\n",
        "      * Understand which features contribute the most to your predictions \n",
        "\n",
        "<br>\n",
        "\n",
        "**OTHER RECENT FEATURES**\n",
        "* **SageMaker in 2021**\n",
        "  * SageMaker Jumpstart\n",
        "    * One-click models and algorithms from model zoos\n",
        "    * Over 150 open source models in NLP, object detections, image classification, etc\n",
        "  * SageMaker Data Wrangler\n",
        "    * Import/transform/analyze/export data within SageMaker Studio\n",
        "  * SageMaker Feature Store\n",
        "    * Find, discover and share features in Studio\n",
        "    * Online (low latency) or offline (for training or batch inference) modes\n",
        "    * Features organized into Feature Groups\n",
        "  * SageMaker Edge Manager\n",
        "    * Software agent for edge devices\n",
        "    * Model optimized with SageMaker Neo\n",
        "    * Collects and samples data for monitoring, labeling and retraining\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER CANVAS**\n",
        "* **What is?**\n",
        "  * No-code ML for business analyst\n",
        "  * Upload csv data (csv only for now), select a column to predict, build it and make predictions\n",
        "  * Can also join datasets\n",
        "  * Classification or Regression\n",
        "  * Automatic data cleaning\n",
        "    * Missing values\n",
        "    * Outliers\n",
        "    * Duplicates\n",
        "  * Share models & datasets with SageMaker Studio\n",
        "* **The Finer Points**\n",
        "  * Local file uploading must be configured \"by your IT administrator\"\n",
        "    * Set up an S3 bucket with appropriate CORS permissions\n",
        "  * Can integrate with Okta SSO (if you want people be able to sign in)\n",
        "  * Canvas lives within a SageMaker Domain that must be manually updated\n",
        "  * Import from Redshift can be set up\n",
        "  * Time series forecasting must be enabled via IAM\n",
        "  * Can run withina VPC\n",
        "  * Pricing is $1.90/hr plus a charge based on number of training cells in a model\n",
        "\n",
        "<br>\n",
        "\n",
        "**BIAS MEASURES IN CANVAS**\n",
        "* **Pre-Training Bias Metrics in Clarify**\n",
        "  * Class Imbalance (CI)\n",
        "    * One facet (demographic group) has fewer training values than another\n",
        "  * Difference in Proportions of Labels (DPL)\n",
        "    * Imbalance of positive outcomes between facet values\n",
        "  * Kullback-Leibler Divergence (KL), Jensen-Shannon Divergence (JS)\n",
        "    * How much outcome distributions of facets diverge\n",
        "  * Lp-norm (LP)\n",
        "    * P-norm difference between distributions of outcomes from facets\n",
        "  * Total Variation Distance (TVD)\n",
        "    * L1-norm difference between distributions of outcomes from facets\n",
        "  * Kolmogorov-Smirnov (KS)\n",
        "    * Maximum divergence between outcomes in distributions from facets\n",
        "  * Conditional Demographic Disparity (CDD)\n",
        "    * Disparity of outcomes between facets as a whole and by subgroups\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER TRAINING COMPILER**\n",
        "* **What is it?**\n",
        "  * Integrated into AWS Deep Learning Containers (DLCs)\n",
        "    * Can't bring your own container\n",
        "  * Compile & optimize training jobs on GPU instances\n",
        "  * Can accelerate trainin up to 50%\n",
        "  * Converts models into hardware-optimizer instructions\n",
        "  * Tested with Hugging Face transformers library, or bring your own model\n",
        "  * Incompatible with SageMaker distributed training libraries\n",
        "  * Best practices:\n",
        "    * Ensure GPU instances are used (ml.p3, ml.p4)\n",
        "    * PyTorch models must use PyTorch/XLAs model save\n",
        "    * Enable debug flag in *compiler_config* parameter to enable debugging  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "e2V4K3hcB4lu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. HIGH-LEVEL ML SERVICES"
      ],
      "metadata": {
        "id": "nvHiWuMBY8BK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**AMAZON COMPREHEND**\n",
        "* **What is it?**\n",
        "  * Natural Language Processing (NLP) and Text Analytics\n",
        "  * Input social media, emails, web pages, documents, transcripts, medical records (Comprehend Medical)\n",
        "  * Extract key phrases, entities, sentiment, language, syntax, topics and document classifications\n",
        "  * Can train on your own data\n",
        "  * Some features:\n",
        "    * *Entities*: it can extract entities in a text, the important objects that exists within that text and categorizes them for you (e.g. \"Seattle\" -> Location, \"Jeff Bezos\" -> Person, etc) with a confidence score of the prediction\n",
        "    * *Key Phrases*: breaking up the sentence into biggest parts (phrases) with confidence score\n",
        "    * *Language*: looking at a text it says what language it is with confidence score\n",
        "    * *Sentiment*: (neutral, positive, negative, mixed) a score of confidence is assigned to these sentiments\n",
        "    * *Syntax*: instead of classifying things on what they are, we're classifying them by the part of speech that they are (proper noun, punctuation, verb, adposition, etc)\n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON TRANSLATE**\n",
        "* **What is it?**\n",
        "  * Use Deep Learning for translation\n",
        "  * Supports custom terminology\n",
        "    * In CSV or TMX format\n",
        "    * Appropriate for proper names, brand names, etc\n",
        "  * It detects the source language in automatic\n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON TRANSCRIBE**\n",
        "* **What is it?**\n",
        "  * Speech to Text\n",
        "    * Input in FLAC, MP3, MP4 or WAV in a specific language\n",
        "    * Streamig audio supported (HTTP/2 or WebSocket)\n",
        "      * French, English or Spanish only\n",
        "  * Speaker Identification\n",
        "    * Specify number of speakers\n",
        "  * Channel Identification\n",
        "    * e.g. two callers could be transcribed separately\n",
        "    * Merging based on timing of \"utterances\"\n",
        "  * Automatic Language Identification\n",
        "    * You don't have to specify a language; it can detect the dominant one spoken\n",
        "  * Custom Vocabularies\n",
        "    * Vocabulary Lists (just a list of special words - names, acronyms)\n",
        "    * Vocabulary Tables (can include \"SoundsLike\", \"IPA\" and \"DisplayAS\")\n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON POLLY**\n",
        "* **What is it?**\n",
        "  * Neural Text-To-Speech, many voices & languages\n",
        "  * Lexicons\n",
        "    * Customize pronunciation of specific words & phrases\n",
        "    * Example: \"World Wide Web Consortium\" instead of \"W3C\"\n",
        "  * SSML\n",
        "    * Alternative to plain text\n",
        "    * Speech Synthetis Markup Language\n",
        "    * Gives control over emphasis, pronunciation, breathing, whispering, speech rate, pitch, pauses\n",
        "  * Speech Marks\n",
        "    * Can encode when sentence/word starts and ends in the audio stream\n",
        "    * Useful for lip-synching animation\n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON REKOGNITION**\n",
        "* **What is it?**\n",
        "  * Computer vision\n",
        "  * Object and scene detection\n",
        "    * Can use your own face collection\n",
        "  * Image moderation\n",
        "  * Facial analysis\n",
        "  * Celebrity recognition\n",
        "  * Face comparison\n",
        "  * Text in image\n",
        "  * Video analysis\n",
        "    * Objects/people/celebrities marked on timeline\n",
        "    * People Pathing\n",
        "* **The Nitty Gritty**\n",
        "  * Images come from S3 or provide image bytes as part of request\n",
        "    * S3 will be faster if the image is already there\n",
        "  * Facial recognition depends on good lighting, angle, visibility of eyes, resolution\n",
        "  * Video must come from Kinesis Video Streams\n",
        "    * H.264 encoded\n",
        "    * 5-30 FPS\n",
        "    * Favor resolution over framerate\n",
        "  * Can use with Lambda to trigger image analysis upon upload\n",
        "* **Rekognition Custom Labels (2020)**\n",
        "  * Train with a small set of labeled images\n",
        "  * Use your own labels for unique items\n",
        "  * Example: the NFL uses custom labels to identify team logos, pylons and foam fingers in images  \n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON FORECAST**\n",
        "* **What is it?**\n",
        "  * Fully-managed service to deliver highly accurate forecasts with ML\n",
        "  * \"AutoML\" chooses best model for your time series data\n",
        "    * ARIMA, DeepAR, ETS, NPTS, Prophet\n",
        "  * Works with any time series\n",
        "    * Price, promotions, economic performance, etc\n",
        "    * Can combine with associated data to find relationship\n",
        "  * Inventory planning, financial planning, resource planning\n",
        "  * Based on \"dataset groups\", \"predictors\" and \"forecasts\"\n",
        "* **Forecast Algorithms**\n",
        "  * *CNN-QR*\n",
        "    * CNN - Quantile Regression\n",
        "    * Best for large datasets with hundreds of time series\n",
        "    * Accepts related historical time series data & metadata\n",
        "    * Very computational expensive model\n",
        "  * *DeepAR+*\n",
        "    * RNN\n",
        "    * Best for large datasets\n",
        "    * Accepts related forward-looking time series & metadata\n",
        "    * Very computational expensive model\n",
        "  * *Prophet*\n",
        "    * Additive model with non-linear trends and seasonality\n",
        "    * Mid range amount of resources needed\n",
        "  * *NPTS*\n",
        "    * Non-Parametric Time Series\n",
        "    * Good for sparse data. Has variants for seasonal/climatological forecasts\n",
        "    * Light model\n",
        "  * *ARIMA*\n",
        "    * AutoRegressive Integrated Moving Average\n",
        "    * Commonly used for simple datasets (< 100 time series)\n",
        "  * *ETS*\n",
        "    * Exponential Smoothing\n",
        "    * Commonly used for simple datasets (< 100 time series) \n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON LEX**\n",
        "* **What is it?**\n",
        "  * Billed as the inner workings of Alexa\n",
        "  * Natural-Language chatbot engine\n",
        "  * A bot is built around Intents\n",
        "    * Utterances invoke intents (\"I want to order a pizza\")\n",
        "    * Lambda functions are invoked to fulfill the intent\n",
        "    * Slots specify extra information needed by the intent\n",
        "      * Pizza side, toppings, crust type, when to deliver, etc\n",
        "  * Can deploy to AWS Mobile SDK, Facebook Messanger, Slack and Twilio\n",
        "* **Amazon Lex Automated Chatbot Designer**\n",
        "  * You provide existing conversation transcripts\n",
        "  * Lex applies NLP & DL, removing overlaps and ambiguity\n",
        "  * Intents, user requests, phrases, values for slots are extracted\n",
        "  * Ensures intents are well defined and separated\n",
        "  * Integrates with Amazon Connect transcripts\n",
        "\n",
        "<br>\n",
        "\n",
        "**AMAZON PERSONALIZE**\n",
        "* **What is it?**\n",
        "  * Fully-managed recommender engine\n",
        "    * Same one Amazon uses\n",
        "  * API access\n",
        "    * Feed in data (purchases, ratings, impressions, cart adds, catalog, user demographics, etc) via S3 or API integration\n",
        "    * You provide an explicit schema in Avro format \n",
        "    * Javascript or SDK\n",
        "    * GetRecommendations\n",
        "      * Recommended products, content, etc\n",
        "      * Similar items\n",
        "    * GetPersonalizedRanking\n",
        "      * Rank a list of items provided\n",
        "      * Allows editorial control/curation (if you want to push specific products)  \n",
        "  * Console and CLI too\n",
        "* **Amazon Personalize Features**\n",
        "  * Real-time or batch recommendations\n",
        "  * Recommendations for new users and new items (the cold start problem)\n",
        "  * Contextual recommendations\n",
        "    * Device type, time, etc\n",
        "  * Similar items\n",
        "  * Unstructured text input\n",
        "  * Intelligent user segmentation\n",
        "    * For marketing campaigns\n",
        "* **Amazon Personalize Terminology**\n",
        "  * Datasets\n",
        "    * Users, Items, Interactions\n",
        "  * Recipes\n",
        "    * USER_PERSONALIZATION\n",
        "    * PERSONALIZED_RANKING\n",
        "    * RELATED_ITEMS\n",
        "  * Solutions\n",
        "    * Trains the model\n",
        "    * Optimizes for relevance as well as your additional objectives\n",
        "      * Video length, price, etc - must be numeric\n",
        "    * Hyperparameter Optimization (HPO - automatic optimization)\n",
        "  * Campaigns\n",
        "    * Deploys your \"solution version\"\n",
        "    * Deploys capacity for generating real-time recommendations\n",
        "* **Amazon Personalize Hyperparameters**\n",
        "  * User-Personalization, Personalized-Ranking\n",
        "    * *hidden_dimension* - (HPO)\n",
        "    * *bptt* - (back-propagation through time - RNN) \n",
        "      * the older is an event is the less it count, this RNN gives more weight to recent things\n",
        "    * *recency_mask* - (weights recent events)\n",
        "    * *min_max_user_history_length_percentile* - (filter out robots) (I don't want to put attention on people who saw few (1 or 2) or a lot of products (2-300))\n",
        "    * *exploration_weight* - 0-1, controls the relevance of your results\n",
        "    * *exploration_item_age_cut_off* - how far back in time you go while you're doing that exploration\n",
        "  * Similar-items\n",
        "    * *item_id_hidden_dimension* (HPO)\n",
        "    * *item_metadata_hidden_dimension* (HPO with min & max range specified) \n",
        "* **Maintaining Relevance**\n",
        "  * Keep your datasets current\n",
        "    * Incremental data import\n",
        "  * Use PutEvents operation to feed in real-time user behaviour\n",
        "  * Retrain the model\n",
        "    * They call this a new *solution version*\n",
        "    * Updates every 2 hours by default\n",
        "    * Should do a full retrain (trainingMode = FULL) weekly\n",
        "* **Amazon Personalize Security**\n",
        "  * Data not shared across accounts\n",
        "  * Data may be encrypted with KMS\n",
        "  * Data may be encrypted at rest in your region (SSE-S3)\n",
        "  * Data in transit between your account and Amazon's internal systems encrypted with TLS 1.2\n",
        "  * Access control via IAM\n",
        "  * Data in S3 must have appropriate bucket policy for Amazon Personalize to process it\n",
        "  * Monitoring & logging via CloudWatch and CloudTrail\n",
        "* **Amazon Personalize Pricing**\n",
        "  * Data ingestion: per GB\n",
        "  * Training: per training-hour\n",
        "  * Inference: per TPS-hour (Transaction Per Second)\n",
        "  * Batch recommendations: per user or per item\n",
        "\n",
        "<br>\n",
        "\n",
        "**OTHER ML SERVICES**\n",
        "* **Amazon Textract**\n",
        "  * OCR (Optical Character Recognition) with forms, fields and table supports\n",
        "  * It's a technology that recognizes text within a digital image\n",
        "* **Amazon DeepRacer**\n",
        "  * RL powered 1/18-scale race car\n",
        "* **Amazon DeepLens**\n",
        "  * Deep Learning-enabled video camera\n",
        "  * Integrated with Rekognition, SageMaker, Polly, Tensorflow, MXNet, Caffè\n",
        "  * It's good for prototyping new ideas\n",
        "* **Amazon Lookout**\n",
        "  * Industrial Application\n",
        "  * Equipment, metrics, vision\n",
        "  * Detects abnormalities from sensor data automatically to detect equipment issues\n",
        "  * Monitors metrics from S3, RDS, Redshift, 3rd party SaaS apps\n",
        "  * Vision uses computer vision to detect defects in silicon wafers, circuit boards, etc\n",
        "* **Amazon Monitron**\n",
        "  * Industrial Application\n",
        "  * End to end system for monitoring industrial equipment and predictive maintenance\n",
        "* **TorchServe**\n",
        "  * Model serving framework for PyTorch\n",
        "  * Part of the PyTorch open source project from Meta (FB)\n",
        "* **Amazon Neuron**\n",
        "  * SDK for ML inference specifically on AWS Inferentia chips\n",
        "  * EC2 Inf1 instance type\n",
        "  * Integrated with SageMaker or whatever else you want (deep learning AMIs, containers, TensorFlow, PyTorch, MXNet)  \n",
        "* **Amazon Panorama**\n",
        "  * Computer vision at the edge\n",
        "  * Like DeepLens but more general\n",
        "  * Brings computer vision to your existing IP cameras\n",
        "* **Amazon DeepComposer**\n",
        "  * AI-powered keyboard\n",
        "  * Composes a melody into an entire song\n",
        "  * For educational purposes\n",
        "* **Amazon Fraud Detector**\n",
        "  * Upload your own historical fraud data\n",
        "  * Builds custom models from a template\n",
        "  * Exposes an API for your online application\n",
        "  * Assess risk from:\n",
        "    * New accounts\n",
        "    * Guest checkout\n",
        "    * \"Try before you buy\" abuse\n",
        "    * Online payments\n",
        "* **Amazon CodeGuru**\n",
        "  * Automated code reviews!\n",
        "  * Finds lines of code that hurt performance\n",
        "  * Resource leaks, race conditions\n",
        "  * Offers specific recommendations\n",
        "  * Powered by ML\n",
        "  * Supports Java and Python\n",
        "* **Contact Lens for Amazon Connect**\n",
        "  * For customer support call centers\n",
        "  * Ingests audio data from recorded calls\n",
        "  * Allows search on calls/chats\n",
        "  * Sentiment Analysis\n",
        "  * Find \"utterances\" that correlate with successful calls\n",
        "  * Categorize calls automatically\n",
        "  * Measure talk speed and interruptions\n",
        "  * Theme detection: discover emerging issues\n",
        "* **Amazon Kendra**\n",
        "  * Enterprise search with Natural Language\n",
        "  * For example: \"Where is the IT support desk?\", \"How do I connect to my VPN?\"\n",
        "  * Combines data from file systems, SharePoint, intranet, sharing services (JDBC, S3) into one searchable repository\n",
        "  * ML-powered - uses thumbs up/down feedback\n",
        "  * Relevance tuning - boost strength of document freshness, view counts, etc\n",
        "  * Alexa's sister? Maybe that's one way to remember it\n",
        "* **Amazon Augmented AI (A2I)**\n",
        " * Human review of ML predictions \n",
        " * Builds workflows for reviewing low-confidence predictions\n",
        " * Access the Mechanical Turk workforce or vendors\n",
        " * Integrated into Amazon Textract and Rekognition\n",
        " * Integrates with SageMaker\n",
        " * Very similar to Ground Truth\n",
        "\n",
        "<br> \n",
        "\n",
        "**PUTTING THE BLOCKS TOGETHER**\n",
        "* Build your own Alexa!\n",
        "  * Transbribe -> Lex -> Polly\n",
        "* Make a universal translator\n",
        "  * Transcribe -> Translate -> Polly\n",
        "* Build a Jeff Bezos detector!\n",
        "  * DeepLens -> Rekognition\n",
        "* Are people on the phone happy?\n",
        "  * Transcribe -> Comprehend                         \n",
        "\n",
        "                                           \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "6JU7xTGsZFEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. ML IMPLEMENTATIONS & OPERATIONS"
      ],
      "metadata": {
        "id": "cvVYzX63lhhV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SAGEMAKER & DOCKER CONTAINERS**\n",
        "* **SageMaker + Docker**\n",
        "  * All models in SageMaker are hosted in Docker containers that are register with ECR\n",
        "    * Pre-built Deep Learning\n",
        "    * Pre-built scikit-learn and Spark ML\n",
        "    * Pre-built Tensorflow, MXNet, Chainer, PyTorch\n",
        "      * Distributed training via **Horovod** or **Parameter Servers**\n",
        "    * Your own training and inference code! Or extend a pre-built image\n",
        "  * This allows you to use any script or algorithm within SageMaker, regardless of runtime or language\n",
        "    * Containers are isolated and contain all dependencies and resources needed to run\n",
        "* **Using Docker**\n",
        "  * Docker containers are created from *images*\n",
        "  * Images are built from a *Dockerfile*\n",
        "  * Images are saved in a *repository*\n",
        "    * Amazon Elastic Container Registry (ECR)\n",
        "* **Structure of a Training Container**\n",
        "  * opt/ml\n",
        "    * input\n",
        "      * config\n",
        "        * hyperparameters.json\n",
        "        * resourceConfig.json\n",
        "      * data\n",
        "        * \\<channel_name>\n",
        "        * \\<input_data>\n",
        "    * model\n",
        "    * code\n",
        "      * \\<script_files>\n",
        "    * output\n",
        "      * failure\n",
        "* **Structure of your Docker Image**\n",
        "  * WORKDIR\n",
        "    * **nginx.conf**: configuration file for the Nginx front end, so basically we're gonna be running a web server and that's how we configure that web server\n",
        "    * **predictor.py**: the program that implements a Flask Web Server for making those predictions at runtime\n",
        "    * **serve/**: the serve directory, that program in there will be started when the container is started from the hosting. That file just launch the Gunicorn server which runs multiple instances of a Flask application that is defined in your *predictor.py*\n",
        "    * **/train**: the train folder contains the program that's invoked when you run the container for training. So to implement your own training algorithm you would modify the program that lives in there \n",
        "    * **wsgi.py**: it's just a small wrapper that's used to invoke your Flask application for serving results\n",
        "* **Assembling it all in a Dockerfile**\n",
        "  * *FROM tensorflow/tensorflow:2.0.0a0*\n",
        "  * *RUN pip install sagemaker-containers*\n",
        "  * *COPY train.py opt/ml/code/train.py*\n",
        "    * \\# Copies the training code inside the container\n",
        "  * *ENV SAGEMAKER_PROGRAM train.py*\n",
        "    * \\# Defines train.py as script entrypoint\n",
        "* **Environment Variables**\n",
        "  * SAGEMAKER_PROGRAM\n",
        "    * Run a script inside opt/ml/code\n",
        "  * SAGEMAKER_TRAINING_MODULE\n",
        "  * SAGEMAKER_SERVICE_MODULE\n",
        "  * SM_MODEL_DIR\n",
        "  * SM_CHANNELS / SM_CHANNEL_*\n",
        "  * SM_HPS / SM_HP_*\n",
        "  * SM_USER_ARGS\n",
        "  * ...and many more\n",
        "* **Using your own Image**\n",
        "  * *cd dockerfile*\n",
        "  * *!docker build -t foo*\n",
        "  * *from sagemaker.estimator import Estimator*\n",
        "    * *estimator = Estimator(image_name='foo', role='SageMakerRole', train_instance_count=1, train_instance_type='local')*\n",
        "    * *estimator.fit()*\n",
        "* **Production Variants**\n",
        "  * You can test out multiple models on live traffic using Production Variants\n",
        "    * Variants Weights tell SageMaker how to distribute traffic among them\n",
        "    * So, you could roll out a new iteration of your model at say 10% variant weight\n",
        "    * Once you're confident in its performance, ramp it to 100%\n",
        "  * This lets you do A/B tests and to validate performance in real-world settings\n",
        "    * Offline validation isn't always useful (e.g. Recommender Systems, where accuracy on people's past behaviour isn't always a good indicator of their performance on future or unseen behaviour)\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER ON THE EDGE**\n",
        "* **SageMakerNeo**\n",
        "  * Train once, run anywhere\n",
        "    * Edge devices\n",
        "      * ARM, Intel, Nvidia processors\n",
        "      * Embedded in whatever - your car?\n",
        "  * Optimizes code for specific devices\n",
        "    * Tensorflow, MXNet, PyTorch, ONNX, XGBoost\n",
        "  * Consists of a compiler and a runtime\n",
        "    * **compiler**\n",
        "      * re-compiles that code into the .py code expected by those edge processors\n",
        "    * **runtime**\n",
        "      * runs on those edge devices to consume that Neo generated code\n",
        "* **Neo + AWS IoT Greengrass**\n",
        "  * Neo-compiled models can be deployed to an HTTPS endpoint\n",
        "    * Hosted on C5, M5, M4, P3 or P2 instances\n",
        "    * Must be same instance type used for compilation\n",
        "  * OR! you can deploy to IoT Greengrass\n",
        "    * This is how you get the model to an actual edge device\n",
        "    * Inference at the edge with local data, using model trained in the cloud\n",
        "    * Uses Lambda inference applications\n",
        "* **Recap**\n",
        "  * **Neo**: compiles your trained model into specific architectures that might be deployed to\n",
        "    * **Edge Devices**\n",
        "    * **IoT Greengrass**\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER SECURITY**\n",
        "* **General AWS Security**\n",
        "  * Use Identity and Access Management (IAM)\n",
        "    * Set up user accounts with only the permissions they nedd\n",
        "  * Use MFA\n",
        "  * Use SSL/TLS when connecting to anything\n",
        "  * Use CloudTrail to log API and user activity\n",
        "  * Use encryption\n",
        "  * Be careful with PII (Personal Identifying Information)\n",
        "* **Protecting Your Data at Rest in SageMaker**\n",
        "  * AWS Key Management Service (KMS)\n",
        "    * Accepted by notebooks and all SageMaker jobs\n",
        "      * Training, tuning, batch transform, endpoints\n",
        "      * Notebooks and everything under *opt/ml* and */tmp* can be encrypted with a KMS key\n",
        "  * S3\n",
        "    * Can use encrypted S3 buckets for training data and hosting models\n",
        "    * S3 can also use KMS\n",
        "* **Protecting Data in Transit in SageMaker**\n",
        "  * All traffic supports TLS/SSL\n",
        "  * IAM roles are assigned to SageMaker to give it permissions to access resources\n",
        "  * Inter-node training communication may be optionally encrypted\n",
        "    * Can increase training time and cost with deep learning\n",
        "    * AKA inter-container traffic encryption\n",
        "    * Enabled via console or API when setting up a training or tuning job\n",
        "* **SageMaker + VPC**\n",
        "  * Training jobs run in a Virtual Private Cloud (VPC)\n",
        "  * You can use a private VPC for even more security\n",
        "    * You'll need to set up S3 VPC endpoints\n",
        "    * Custom endpoint policies and S3 bucket policies can keep this secure\n",
        "  * Notebooks are Internet-enabled by default\n",
        "    * This can be a security hole\n",
        "    * If disabled, your VPC needs an interface endpoint (PrivateLink) or NAT Gateway and allow outbound connections for training and hosting to work\n",
        "  * Training and Inference Containers are also Internet-enabled by default\n",
        "    * Network isolation is an option but this also prevents S3 access\n",
        "* **SageMaker + IAM**\n",
        "  * User permissions for:\n",
        "    * CreateTrainingJob\n",
        "    * CreateModel\n",
        "    * CreateEndpointConfig\n",
        "    * CreateTransformJob\n",
        "    * CreateHyperParameterTuningJob\n",
        "    * CreateNotebookInstance\n",
        "    * UpdateNotebookInstance\n",
        "  * Predefined policies:\n",
        "    * AmazonSageMakerReadOnly\n",
        "    * AmazonSageMakerFullAccess\n",
        "    * AdministratorAccess\n",
        "    * DataScientist\n",
        "* **SageMaker Logging and Monitoring**\n",
        "  * CloudWatch can log, monitor and alarm on:\n",
        "    * Invocations and latency of endpoints\n",
        "    * Health of instance nodes (CPU, memory, etc)\n",
        "    * Ground Truth (active workers, how much they are doing)\n",
        "  * CloudTrail records actions from users, roles and services within SageMaker\n",
        "    * Log files delivered to S3 for auditing\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER RESOURCES MANAGEMENT**\n",
        "* **Choosing Your Instance Types**\n",
        "  * We covered this under \"modeling\" even though it's an operations concern\n",
        "  * In general, algorithms that rely on deep learning will benefit from GPU instances (P2 or P3) for training\n",
        "  * Inference is usually less demanding and you can often get away with compute instances there (C4, C5)\n",
        "  * GPU instances can be really pricey\n",
        "* **Managed Spot Training**\n",
        "  * Can use EC2 Spot Instances for training\n",
        "    * Save up to 90% over on-demand instances\n",
        "  * Spot instances can be interrupted!\n",
        "    * Use checkpoints to S3 so training can resume\n",
        "  * Can increase training time as you need to wait for spot instances to become available \n",
        "* **Elastic Inference**\n",
        "  * Accelerates deep learning inference\n",
        "    * At fraction of cost of using a GPU instance for inference\n",
        "  * EI accelerators may be added alongside a CPU instance\n",
        "    * ml.eia1.medium/large/xlarge\n",
        "  * EI accelerators may also be applied to notebooks\n",
        "  * Works with Tensorflow, PyTorch and MXNet pre-built containers\n",
        "    * ONNX may be used to export models to MXNet\n",
        "  * Works with custom containers built with EI-enabled Tensorflow, PyTorch or MXNet\n",
        "  * Works with Image Classification and Object Detection built-in algorithms\n",
        "* **Automatic Scaling**\n",
        "  * You set up a scaling policy to define target metrics, min/max capacity and cooldown periods\n",
        "  * Works with CloudWatch\n",
        "  * Dynamically adjusts number of instances for a production variant\n",
        "  * Load test your configuration before using it!\n",
        "* **SageMaker and Availability Zones**\n",
        "  * SageMaker automatically attempts to distribute instances across availability zones\n",
        "  * But you need more than one instance for this to work!\n",
        "  * Deploy multiple instances for each production endpoint\n",
        "  * Configure VPCs with at least two subnets, each in a different AZ\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER SERVERLESS INFERENCE**\n",
        "* **Serverless Inference**\n",
        "  * Introduced in 2022\n",
        "  * Specify your container, memory requirement, concurrency requirements\n",
        "  * Underlying capacity is automatically provisioned and scaled\n",
        "  * Good for infrequent or unpredictable traffic; will scale down to zero when there are no requests\n",
        "  * Charged based on usage\n",
        "  * Monitor via CloudWatch\n",
        "    * ModelSetupTime, Invocations, MemoryUtilization\n",
        "* **AWS SageMaker Inference Recommender**\n",
        "  * Recommends best instance type & configuration for your models\n",
        "  * Automates load testing model tuning\n",
        "  * Deploys to optimal inference endpoint\n",
        "  * How it works:\n",
        "    * Register your model to the model registry\n",
        "    * Benchmark different endpoint configurations\n",
        "    * Collect & visualize metrics to decide on instance types\n",
        "    * Existing models from zoos may have benchmark already\n",
        "  * Instance Recommendations\n",
        "    * Run load tests on recommended instance types\n",
        "    * Takes about 45 minutes\n",
        "  * Endpoint Recommendations\n",
        "    * Custom load test\n",
        "    * You specify instances, traffic patterns, latency requirements, throughput requirements\n",
        "    * Takes about 2 hours\n",
        "\n",
        "<br>\n",
        "\n",
        "**SAGEMAKER INFERENCE PIPELINES**\n",
        "* **Inference Pipelines**\n",
        "  * Linear sequence of 2-15 containers\n",
        "  * Any combinantion of pre-trained built-in algorithms or your own algorithms in Docker containers\n",
        "  * Combine pre-processing, predictions, post-processing\n",
        "  * Spark ML and scikit-learn containers OK\n",
        "    * Spark ML can be run with Glue or EMR\n",
        "    * Serialized into MLeap format\n",
        "  * Can handle both real-time inference and batch transforms\n"
      ],
      "metadata": {
        "id": "bHaBvM8wintn"
      }
    }
  ]
}